{
    "poll_list": [],
    "discourse_list": [
        {
            "thread_link": "https://forum.makerdao.com/t/towards-web3-native-intelligence-tools-for-protocol-comprehension-and-stewardship/15642",
            "title": "Towards web3-native intelligence: tools for protocol comprehension and stewardship ",
            "index": 15642,
            "category": [
                "Governance",
                "Proposal Ideas"
            ],
            "tags": [
                "idea",
                "defi",
                "ust",
                "dashboard"
            ],
            "content": [
                {
                    "author_link": "https://forum.makerdao.com/u/pvl",
                    "index": "#1",
                    "likes": "8",
                    "time": "06/06/2022-22:21:42",
                    "content": "I\u2019m working on web3/DeFi-native modelling and am seeking funding + colab opportunities for the next stage. Wanted to gauge community mood regarding match of interests before submitting formal applications.  TL;DR A web3 protocol is an evolving shared narrative: it lives simultaneously in two domains open for exploration, onchain transactions and community interactions. They inform and impact each other in both directions in a myriad of ways creating a bipartite heterogenous living organism. To comprehend and be able to predict this organism means to be able to model and predict evolution of its two integral parts in a coherent, unified way. Currently available intelligence tools don\u2019t leverage web3 nature, but merely translate approaches from web2/TradFi, hence falling short of providing deep insight. This proposal strives to make the first crucial step towards solving this problem.  web3/DeFi intelligence at the moment is at the skeuomorphic stage \u2014 web2/TradFi tools like SQL data queries, basic accounting, node ranking, outdated VaR risk modelling, agent-based modelling backed by the rational choice theory are translated as if there\u2019s no fundamental difference between TradFi, where part of data is simply not digitised, and the bulk of digital data is private, and web3, which leaves opportunities for insight provided by the latter unexplored. Expanding on a16z\u2019 Chris Dixon we can postulate that a web3 protocol with its products is an evolving shared narrative: be it a token, NFT, web3 games, decentralized social media, or any yet to be invented thing, its utility and value is a function of a changing commonly shared narrative, where the essence of the narrative, the nature of changes and commonality play equally important parts. A web3 protocol lives simultaneously in two domains open for exploration: onchain transactions and community interactions. They inform and impact each other in both directions in a myriad of ways creating a bipartite heterogenous living organism. Loop: people engage in discussions, track discussions, track onchain data, make decisions, execute transactions, other people track these decisions and rationalisations and make their own decisions. To know and comprehend this organism means to be able to model and predict evolution of its two integral parts in a coherent, unified way. Luckily, in DeFi both financial and contextual data, transactions and public sentiment about them on Twitter/Discord/Discourse, is fully open and available for modelling and insight. Hence, in DeFi/web3 we can build native decision making around native, non-skeuomorphic intelligence. Specifically, two major opportunities here are to learn models from real time data of public sentiment towards specific protocols/products and learn models from onchain data with vault-level granularity. And since they impact each other supermodels uniting both forces can be built as well.  UST sentiment => crash case  A few words about opportunities around sentiment. Why sentiment matters? The recent UST crash was the result of a gradual crowd sentiment deterioration => loss of confidence => panic => bank run => death spiral supported by the mechanics of the protocol. We just witnessed how public sentiment dynamics wiped off $40 bln of value over several days.      Twitter scraping code || Raw tweet data Language model: BERT_base model (12-layer, 768-hidden, 12-heads, 110M parameters), RoBERTa pretraining procedure. Pretrained on the corpus of 850M English Tweets (16B word tokens ~ 80GB) streamed from 01/2012 to 08/2019. Fine-tuned for sentiment analysis with the SemEval-2017: Task 4A dataset. Sentiment analysis code || Sentiment data: result of sentiment analysis || Visualise the result  Rest assured it\u2019s not an isolated case. Already in 2010 it was shown that the accuracy of a model predicting daily closing values of Dow Jones Industrial Average is significantly improved by the inclusion of specific public mood dimensions as measured from Twitter feed. Moreover, realising the importance of public mood TradFi public institutions, including Federal Reserve and World Bank, are tracking public sentiment. Back in 2010 sentiment was measured with a fixed lexicon, now we can use large language models fine-tuned with domain-specific annotated datasets, which would provide precision insight into events like. UST crash. Models learned from social networks & onchain time series can also be used in asset management and broader DAO decision making mapping public mood and onchain dynamics to (future) TVL, usage or token price, discovering patterns of challenges and opportunities, running simulations, optimising vault design and parameter set. Among many other things. For instance, UST crash provides an excellent dataset of matching sentiment and onchain dynamics of real-time DeFi-native panic pattern, which could be learned into a model and used to discover future similar cases.  PROPOSAL  The big opportunity here is to design, build and train a model, which intakes community and onchain data relevant to the protocol/product and outputs respective evolving shared narrative. Then build decision support tools around this web3-native intelligence.      I demonstrated above a proof of concept. To move it towards production progress should go in a number of parallel ways. The first stage \u2014 three-four months \u2014 of this work will encompass the following :  I. Build a custom DeFi-focused annotated community interactions dataset to fine-tune a large language model for multidimensional affect analysis  To gauge public sentiment I use a general purpose language model pretrained on the large corpus of texts and then fine-tuned with the SemEval-2017: Task 4A dataset for sentiment analysis. The result is impressive, but we can get far deeper and richer insight. Currently state-of-the-art natural language processing results are achieved with Transformer-based large language models (OpenAI\u2019s GPT-3 \u2014 175B, DeepMind\u2019s Gopher \u2014 280B params). Until most recently such models were accessible only to the BigTech, but the Big Science project is changing the game: an international non-profit consortium is working on the SoA multilingual (46 langs) BLOOM LLM, 176B params, pretrained on 350B words, which will be fully open from day one. Pretraining started on May, 11 and will finish within 3-4 months. It\u2019s our chance to ride the wave. To leverage the full potential of this opportunity we need to use coming months to get prepared: build a custom DeFi-native labelled community interactions dataset to fine-tune BLOOM LLM for our purposes. DeFi conversation on Twitter/Discord/Discourse is full of domain-specific slang, nuances, deep context and a general purpose model must understand these details natively to output the most adequate results. Moreover, the SemEval-2017-4A dataset, although popular, contains 50k tweets and only 3 classes of sentiment (positive/neutral/negative). The bigger dataset for fine-tuning is the better results our model will produce. So we\u2019ll use the most recent DynaSent sentiment analysis benchmark dataset as a size reference (130k). Also, clearly affect expressed by people is far more nuanced than what could be captured by a three-class scale, which will be reflected in a bigger, more nuanced scale.      Although there are multiple commercial companies offering data labelling services, it\u2019s been shown that retail annotated datasets contain systemic labelling errors. This is especially urgent for us given that we\u2019re looking into identifying affect of a tweet/post. Hence, we need to assemble a group of handpicked amply qualified annotators, train them to properly understand DeFi landscape and instruct them to annotate a dataset assembled from Twitter/Discord/Discourse discussions with labels reflecting mood of each tweet or post. We\u2019ll be using Heartex to run bespoke labelling. Nobody has ever assembled such dataset for DeFi; if performed, this asset will give us a huge edge; this investment will bring immense return down the road. Future versions of the community mood model could be enriched with a community social graph data. Pure language models presume that all social interactions influence equally the state of community mood, which is clearly not the case. A message from a protocol founder vs an average troll clearly should have different weight in the resulting picture. One way to approach this is to use a Temporal Graph Network (TGN) to represent an evolving community graph. TGN generates temporal embedding (a real-valued vector) for each user (graph node) i. This embedding is a learnable function of their history of interactions (messages) and that of their n-hop neighbours (social ties akin to PageRank).  II. DL experiments on the second component of the Big model, the vault-level model of onchain transactions.  A Spatio-Temporal Graph Network (STGN) can be used to represent an evolving graph of onchain transactions. Here, say for a given vault, STGN generates a temporal embedding (a real-valued vector) for each wallet (graph node) i. This embedding is a learnable function of their history of transactions (messages) and that of their n-hop neighbours:      A network (ETH)-wide representation graph can also be built. A vault model can be used for prediction: running test scenarios for different assets/platforms/DAO decision parameter sets; classification: risk/value profiling assets/platforms. Tx patterns forecasting. Fraudulent activity detection. Detecting other patterns/clusters on the trie providing certain insights and serving as a decision support tool for all stakeholders: DAOs, investors, community members, users. I invite everybody to brainstorm further possible applications. Again, to the best of my knowledge nobody has ever done this before, this is an investment with huge potential return. The most interesting and complicated part further down the road is to merge two components of the bipartite web3 model. One approach: both models can be regarded as functions, each in their respective function space. Then temporal evolution of these models can be modeled as an operator on this function space; then a learnable mapping between these function spaces will be a representation of mutual impact of community life and onchain transactions bringing unity we\u2019re seeking here. Another approach: use Bayesian Networks to identify mutual causation. I\u2019ve studied under Prof. Michael Bronstein, a specialist in geometric DL and Head of Graph Learning Research at Twitter, and I plan to reach out to him regarding this project; his expertise would be particularly helpful here.  III. Finally, build a UX/UI design concept to get adequate insight into the data.  All data and models in the world are worthless in the absence of adequate HCI tools. We must be able to dive into the evolving narrative about community mood and its bijective mapping to the onchain dynamics in an effortless, yet profound way. For this part I plan to bring in the art director I know personally. He is responsible, among many other projects, for the Offshore pipeline management system interface for South Stream (iF Design Award '22; Red Dot Design Award '21)          and Moscow Metro map 3.0 (iF Design Award '17)      The purpose of this part of the proposal is to create a concept of a design system/design language, which will later be leveraged to build an interface into the shared evolving narrative. The concept will be built in Unreal Engine, it will be a live simulation aka infinite game-inspired tool for diving into the evolving shared narrative == a web3 product.      It will also hopefully bring some good publicity once built. A recently published DeepMind\u2019s Gato model represents an early step towards what I\u2019m implying as a horizon for this proposal: a multi-modal, multi-task model, which intakes heterogenous data, like social network discussions and onchain data time series, and outputs an integrative domain-specific prediction like a shared narrative regarding a certain topic over a certain period. ",
                    "links": [
                        "https://dune.com/browse/dashboards",
                        "https://llama.xyz/",
                        "https://nansen.ai/",
                        "https://tribe.fei.money/t/further-analysis-of-tribe-turbo-with-gauntlet/3970/7",
                        "https://maker.blockanalitica.com/",
                        "https://gauntlet.network/",
                        "https://tribe.fei.money/t/further-analysis-of-tribe-turbo-with-gauntlet/3970/6",
                        "https://cdixon.mirror.xyz/977Uy2b3ZWCNjVdHxeaNC2ecYOUS3VPgS2_PwVddiQ0",
                        "https://future.a16z.com/podcasts/play-to-earn-gaming-and-how-work-is-evolving-in-web3/",
                        "https://a16z.com/2019/08/29/social-networking-2030-crypto-regulatory-summit/",
                        "https://decrypt.co/100402/how-terra-ust-luna-imploded-crypto-crash",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/eb7bd53f60ff210f36a7ef24e8d7860ee09045c2.png",
                        "https://deepnote.com/workspace/pk-1fde954a-ebc5-4f4a-9398-c5ca85b77dfb/project/Towards-web3-intelligence-proposal-15d0a44b-0ce2-48db-bb36-d259e1fedf6b/%2Fnotebook.ipynb",
                        "https://drive.google.com/file/d/1oEZR5Pf1i51o4GgFmT2zD2WczbS4HoYk/view?usp=sharing",
                        "https://drive.google.com/drive/folders/1nAEdjYZsJzfG9H2ud4kr9itOgjoUc-z4?usp=sharing",
                        "https://colab.research.google.com/drive/1MoJh4kTVWX4hIj7wOrh9pGVjis-t1bH9?usp=sharing",
                        "https://drive.google.com/file/d/1X1dgnaIf4koTafLsQlbOMKq_N3wSKYA-/view?usp=sharing",
                        "https://observablehq.com/@pvl/towards_web3_intelligence_proposal",
                        "https://arxiv.org/abs/1010.3003",
                        "https://www.newyorkfed.org/microeconomics/sce/background.html",
                        "https://ieg.worldbankgroup.org/sites/default/files/Data/Topic/UsingTwitterData.pdf",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/b433e7a3321d2baff81b05504111f6be86439cce.png",
                        "https://lena-voita.github.io/nlp_course/language_modeling.html",
                        "https://commoncrawl.org/",
                        "https://aclanthology.org/S17-2088.pdf",
                        "https://gluebenchmark.com/leaderboard",
                        "https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)",
                        "https://huggingface.co/blog/large-language-models",
                        "https://bigscience.huggingface.co/",
                        "https://arxiv.org/abs/2012.15349",
                        "http://ai.stanford.edu/~amaas/papers/conditioned-sentiment-expression.pdf",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/21fdb3066d370809f10a3bfee8e83272dff3a861.jpeg",
                        "https://labelerrors.com/",
                        "https://heartex.com/product",
                        "https://d2kq0urxkarztv.cloudfront.net/6130cc83941c6200a154ea23/3104296/upload-17923e5b-6bc8-478e-a72e-2da2cd2d6091.png?cX=0&cY=1&cW=1150&cH=1369",
                        "https://en.wikipedia.org/wiki/Bayesian_Network",
                        "https://en.wikipedia.org/wiki/Michael_Bronstein",
                        "https://www.artlebedev.com/turkstream/interface/",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/dac677faf4d01529ed1f261730d1abf9c0a92be0.jpeg",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/58c5c0b449943242fb39040d6dd8b6072afc1357.jpeg",
                        "https://www.artlebedev.com/metro/map3/",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/d792b0e12299772fde1a5388b9e1cc40544d7bff.jpeg",
                        "https://www.unrealengine.com/en-US",
                        "http://iancheng.com/emissaries",
                        "https://aws1.discourse-cdn.com/standard20/uploads/gro/original/1X/a063ad21dba381fc0619edd6b68b15c5e3ab76f1.jpeg",
                        "https://arxiv.org/abs/2205.06175",
                        "https://forum.makerdao.com/t/mip55c3-sp10-pioneer-a-defi-native-dataset-for-modelling-sentiment-driven-dynamics-and-risks-spf/17942",
                        "https://forum.makerdao.com/t/pvl-delegate-platform/16022",
                        "https://forum.makerdao.com/t/mip55c3-sp11-pioneer-defi-focused-language-dataset-for-the-benefit-of-risk-modelling-govcomms/18802/13",
                        "https://forum.makerdao.com/t/mip55c3-sp11-pioneer-defi-focused-language-dataset-for-the-benefit-of-risk-modelling-governance-communication/18802",
                        "https://forum.makerdao.com/t/forum-at-a-glance-june-02-08-2022/15703",
                        "https://forum.makerdao.com/t/the-endgame-party-delegate-signup/15852/47",
                        "https://forum.makerdao.com/t/governance-and-risk-194-thursday-june-09-at-17-00-utc/15664/2",
                        "https://forum.makerdao.com/t/mip55c3-sp10-pionero-de-un-conjunto-de-datos-defi-nativos-para-modelar-la-dinamica-y-los-riesgos-impulsados-por-los-sentimientos-traduccion/17949"
                    ],
                    "GPT-summary": "The author is proposing to design, build, and train a model that intakes community and on-chain data relevant to the protocol/product and outputs respective evolving shared narrative. The proposal aims to make the first crucial step towards solving the problem of web3-native intelligence tools for protocol comprehension and stewardship. The author is seeking funding and collaboration opportunities for the next stage and is explaining the proposal in detail. The post also includes constructive criticism and suggestions for future work, as well as advertising the proposal and inviting questions.",
                    "GPT-proposal-categories": null,
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "3rd party or author wants to collaborate on proposal",
                        "3rd party or author is advertising proposal"
                    ],
                    "Sentiment": 5.5464272893070365
                },
                {
                    "author_link": "https://forum.makerdao.com/u/psychonaut",
                    "index": "#2",
                    "likes": "5",
                    "time": "06/06/2022-23:38:18",
                    "content": "This proposal is way over my head and probably nobody on the forum has much idea what you\u2019re talking about. However, I\u2019m really happy that you posted here. I think this degree of sophistication add a inscrutable flourish to the forum atmosphere.  ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party giving constructive criticism of proposal",
                        "3rd party extending to proposal",
                        "3rd party asking questions about proposal",
                        "3rd party or author is advertising proposal"
                    ],
                    "Sentiment": 7.5
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Allan_Pedersen",
                    "index": "#3",
                    "likes": "3",
                    "time": "07/06/2022-07:43:26",
                    "content": "Hi @pvl Welcome to the Maker Forum! I like the ambitiousness of this. I wonder if making a high-value, quicker start analysis/tool at this might make sense? Some results to build your larger ambitions on? IMO, for Maker, the high-value subject for analysis/tools is \u201cpeg trust\u201d. I.e. questions such as \u201cwhat is the level of trust right now?\u201d, \u201cwhat is an alarming level of trust?\u201d, \u201cwhat actions increase/decrease trust?\u201d, \u201cwhat are leading indicators for change in trust?\u201d, etc. I believe sentiment analysis - on a combination of datasets - not just Defi I suppose - could start trying to answer this sort of question? Mood/sentiments may not quite be the same as trust, but surely they must be linked. (i.e. I trust my bank to keep my money safe, but my feelings about them go up and down\u2026) I imagine a project to \u201ctool up\u201d Maker in respect of understanding and monitoring this \u201cPeg Trust\u201d from a sentiment point of view might have some community support. And I wonder if it might be a more focused and quicker way to get started for you? Exciting stuff indeed! And thank you for bringing your thoughts and ideas to the Maker Forum. It is thoroughly appreciated. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party giving constructive criticism of proposal",
                        "3rd party extending to proposal",
                        "3rd party asking questions about proposal",
                        "3rd party or author is advertising proposal"
                    ],
                    "Sentiment": 6.289186507936508
                },
                {
                    "author_link": "https://forum.makerdao.com/u/pvl",
                    "index": "#4",
                    "likes": "4",
                    "time": "07/06/2022-11:07:45",
                    "content": "Thanks @Allan_Pedersen! I agree: ironically, Maker as well as DeFi at large, turns out to be in the trust business. It\u2019s just that trust here concerns technical and organisational/cultural reliability, a stablecoin being a trust-driven financial vehicle. You use DAI as a means of payment, storage of value because you\u2019re confident about technical and cultural sustainability of the MakerDAO, it\u2019s ability to build and maintain stability of its products. Realistically, users at large don\u2019t look into code or read this forum \u2013 they just have certain attitude towards the organisation, its products and its prospects. The key component of the UST drama (why now?) was loss of confidence and a bank run => death spiral enabled by the mechanics of the protocol. So basically it fits into the framework I\u2019m talking about above. Hence, trust/confidence/positive attitude/outlook are key driving forces behind DeFi product adoption and its future, as well as economic activity at large. It influences onchain transactions and being influenced by them. This could be both an opportunity and a risk. For Maker products, collaterals etc. That\u2019s why I think such tool may well at least augment input of Block Analitica, @Risk-Core-Unit or like what Gauntlet has done for Maker. Take Gauntlet as an example. What\u2019s Gauntlet\u2019s approach?    Medium \u2013 15 Feb 22    Gauntlet\u2019s Model Methodology This post is the second in a series giving deeper insight into Gauntlet\u2019s methodology. Our previous article details how we make parameter\u2026  Reading time: 7 min read       In a nutshell:  At a high level, ABS allows a set of \u2018agents\u2019 (pieces of code meant to mimic actual user behavior) to make rational actions against DeFi protocols according to some \u2018what-if\u2019 market scenario.  How close is this mimicked user behaviour to the actual user behaviour?  Each agent acts according to a set of rules to carry out rational (profit-maximizing) actions.  That\u2019s basically XIXth century economics. The UST crash case, as I demonstrate above, is an example of emotions (a gradual crowd sentiment deterioration => loss of confidence => panic => bank run => death spiral) having impact on the financial and economic activity. Nobel Prizes have already been given out for debunking the pure rational choice theory: Richard Thaler: for his pioneering work in establishing that people are predictably irrational \u2014 that they consistently behave in ways that defy economic theory. Daniel Kahneman: for having integrated insights from psychological research into economic science, especially concerning human judgment and decision-making under uncertainty See also Robert Shiller Behavioral economics The approach employed by Gauntlet was developed for TradFi, where the bulk of real life data is either not digitised at all (much of the b2c interaction happens offline) or isn\u2019t available (much of market data is private). Hence, agent-based modelling with theoretical assumptions about incomplete data is justifiable. However, for DeFi agent-based only modelling is a suboptimal legacy framework. Since all data about transactions and user interactions with the protocol is open and available for modelling, we can learn from real life data a model of a living protocol, or parts of it, and models of user interactions with it. Moreover, this model will be continuously fine-tuned with new data emerging. Gauntlet is using VaR as a risk measure.    Medium \u2013 28 Jan 22    VaR Deepdive tl;dr We have updated our Risk Dashboards and have split our existing VaR into insolvencies (new definition of VaR) and liquidations\u2026  Reading time: 7 min read       In fact, it\u2019s outdated and being phased out in financial stress-test simulations due to its inability to capture tail risk in favour of Expected Shortfall. Just to give some perspective here is a quote from \u201cA revised market risk framework\u201d  published by the Basel Committee on Banking Supervision (kinda regulation/overseeing body for word\u2019s central banks):  Move from Value-at-Risk (VaR) to Expected Shortfall (ES): A number of weaknesses have been identified with using VaR for determining regulatory capital requirements, including its inability to capture \u201ctail risk\u201d. For this reason, the Committee proposed in May 2012 to replace VaR with ES. ES measures the riskiness of a position by considering both the size and the likelihood of losses above a certain confidence level. The Committee has agreed to use a 97.5% ES for the internal models-based approach and has also used that approach to calibrate capital requirements under the revised market risk standardised approach.  That was almost 10 years ago. To sum up in Gauntlet\u2019s own words:  $38 billion in assets now depend on Gauntlet\u2019s financial modeling framework, signaling that the financial systems of the future are those that bridge the gap between the transparency of crypto with the risk mitigation tactics of traditional finance (TradFi).  Couldn\u2019t agree less. DeFi needs its own native risk mitigation tactics rooted in its open and decentralised nature and leveraging opportunities provided by it. The fact that Gauntlet still dominates DeFi risk management is worrisome, but it could also be an edge for a forward looking DAO. So, basically, the purpose of my post is to ask whether Maker would be interested to explore the avenue I\u2019m suggesting, and ask for help in formalising this cooperation. Actually, ideally it would be a cross-protocol initiative. ",
                    "links": [
                        "https://forum.makerdao.com/t/link-a-liquidations-2-0-parameters/7180/10",
                        "https://medium.com/gauntlet-networks/gauntlets-model-methodology-ea150ff0bafd",
                        "https://medium.com/gauntlet-networks/gauntlets-model-methodology-ea150ff0bafd",
                        "https://en.wikipedia.org/wiki/Richard_Thaler",
                        "https://en.wikipedia.org/wiki/Daniel_Kahneman",
                        "https://en.wikipedia.org/wiki/Robert_J._Shiller",
                        "https://en.wikipedia.org/wiki/Behavioral_economics",
                        "https://medium.com/gauntlet-networks/var-deepdive-b4a9b6097e9f",
                        "https://medium.com/gauntlet-networks/var-deepdive-b4a9b6097e9f",
                        "https://www.bis.org/publ/bcbs265.pdf",
                        "https://medium.com/gauntlet-networks/announcing-our-1-billion-valuation-and-next-steps-for-the-gauntlet-platform-d1d3ebe7fa0d",
                        "https://cdixon.mirror.xyz/0GBv9WRI-LQE6F4r2gGczG6AVeFlNuvt3HETHZ5A93U",
                        "https://forum.makerdao.com/t/mip55c3-sp10-pioneer-a-defi-native-dataset-for-modelling-sentiment-driven-dynamics-and-risks-spf/17942",
                        "https://forum.makerdao.com/t/mip55c3-sp10-pionero-de-un-conjunto-de-datos-defi-nativos-para-modelar-la-dinamica-y-los-riesgos-impulsados-por-los-sentimientos-traduccion/17949"
                    ],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "None of the topics listed match"
                    ],
                    "Sentiment": 5.432583956447593
                },
                {
                    "author_link": "https://forum.makerdao.com/u/flipflopflapdelegate",
                    "index": "#5",
                    "likes": "1",
                    "time": "07/06/2022-12:15:33",
                    "content": "Shouldn\u2019t the model also detect when there\u2019s over-euphoria? Like when everyone and their dog owns an NFT, or 6 mortgages with a 550 FICO score?  And how do you detect the bots on Twitter that the Lunatics (TerraLuna) were running and keep track of the TikTok \u201cinfluencers\u201d that were pumpin\u2019 Luna\u2026 What about modeling for podcasters\u2014will voice recognition also play a role? BTW, the Gato agent is mind-boggling: A Generalist Agent ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party giving constructive criticism of proposal",
                        "3rd party asking questions about proposal",
                        "3rd party extending to proposal",
                        "None of the topics listed match"
                    ],
                    "Sentiment": 7.5
                },
                {
                    "author_link": "https://forum.makerdao.com/u/pvl",
                    "index": "#6",
                    "likes": "1",
                    "time": "07/06/2022-12:58:41",
                    "content": "sure, there are multiple ways this work can go forward. I\u2019ve outlined some of them in the initial post.     flipflopflapdelegate:  Shouldn\u2019t the model also detect when there\u2019s over-euphoria? Like when everyone and their dog owns an NFT, or 6 mortgages with a 550 FICO score?   the more nuanced your mood state space is, the more details you can detect. for now I used the simplest [positive; neutral; negative] scale as a proof-of-concept, both for practical and financial reasons.     flipflopflapdelegate:  And how do you detect the bots on Twitter that the Lunatics (TerraLuna) were running   for now: heuristics. after scraping twitter I rank users by the number of their tweets in the dataset and filter out those, which I recognise as obvious bots. in future versions we can introduce a community social graph data: user\u2019s input is multiplied by their weight as a function of their community standing (akin to PageRank). Obviously messages from protocol core contributors and average trolls should be weighted differently. I briefly mention using Temporal Graph Network model to represent an evolving community graph. another approach: use DL on graphs algos to detect trolls by patterns of message propagation. Actually this technology was developed by a student of Prof. Bronstein, I studied under him. Twitter later acquired their startup to fight fake news in the feed.     flipflopflapdelegate:  keep track of the TikTok \u201cinfluencers\u201d that were pumpin\u2019 Luna\u2026       flipflopflapdelegate:  What about modeling for podcasters\u2014will voice recognition also play a role?   I scraped Twitter feed only. Discord & Discourse are in the pipeline. Anyhow I have a personal subjective feeling that Twitter is a good representation of the whole web3 space. All leaders and newcomers are there, all important issues are discussed there. Even if something originates elsewhere, it finds fair reflection on Twitter. Building a DeFi-native dataset with nuanced mood space to fine-tune a language model to understand DeFi slang and context properly; training relevant models on cloud computing services and building a decision support tool giving insight into the model\u2019s output (not just a bunch of murky graphs) requires funding. That\u2019s why I\u2019m approaching a DAO. ",
                    "links": [
                        "https://blog.twitter.com/en_us/topics/company/2019/Twitter-acquires-Fabula-AI"
                    ],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "3rd party or author wants to collaborate on proposal"
                    ],
                    "Sentiment": 5.448322510822511
                },
                {
                    "author_link": "https://forum.makerdao.com/u/LongForWisdom",
                    "index": "#7",
                    "likes": "2",
                    "time": "07/06/2022-13:08:46",
                    "content": "Would such a system be able to output effective and accurate summaries of forum threads / discussions? GPT3 is apparently able to achieve this using recursive summarization on books - but I suspect that it would fail on DeFi-specific content due to the bespoke meanings and terminology. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party asking questions about proposal",
                        "3rd party giving constructive criticism of proposal",
                        "3rd party extending to proposal",
                        "None of the topics listed match",
                        "None of the topics listed match"
                    ],
                    "Sentiment": 5.982142857142857
                },
                {
                    "author_link": "https://forum.makerdao.com/u/pvl",
                    "index": "#8",
                    "likes": "2",
                    "time": "07/06/2022-14:29:12",
                    "content": "Right, large language models do summarisation, yes. The beauty of BLOOM LLM, apart from most probably being better than GPT3, (176b vs 175b params, architecture improvements from lessons learned over 2 years, 46 langs vs English-only), is that it will be fully open, first of its kind. GPT3 is private, you can access it only via api  for fine-tuning being fully dependent on OpenAI. Plus kinda against web3 ethos. So having a corpus of DeFi-native texts you can basically train the model to understand DeFi context and output adequate results. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "3rd party or author is advertising proposal"
                    ],
                    "Sentiment": 6.341666666666667
                },
                {
                    "author_link": "https://forum.makerdao.com/u/pvl",
                    "index": "#9",
                    "likes": "1",
                    "time": "07/06/2022-15:06:10",
                    "content": "UPD I initiated a similar discussion on Aave\u2019s forum.    Aave \u2013 7 Jun 22    Towards web3-native intelligence: tools for protocol comprehension and... Feels best as an Aave Grants proposal - what is the size of your ask?  This is an important aspect that it is lacking.  I would caution against copying and pasting proposals across different DAOs. Not once does your proposal mention Aave or convey...      Ideally this should be a cross-protocol initiative akin to the DeFi Education fund. Because obviously creating a DeFi-focused dataset for fine-tuning a general purpose language model as well as modelling onchain transactions and designing decision support tools serves interests of everybody in DeFi. I didn\u2019t discuss it from the start because it\u2019s kinda a logistical issue, which comes after principle issues. But if at least major players chipped in, Aave, Compound, Maker, Uniswap, it would be easier for everybody + everybody will be able to benefit from it. It\u2019d work for the whole industry. As for the concrete numbers, it will certainly depend on the goals, but I\u2019d say around 200k for the first 3-4 months, the bulk going for one-time investment like building a DeFi-native mood analysis dataset or cloud computing expenses for the first iteration of onchain transactions modelling. ",
                    "links": [
                        "https://governance.aave.com/t/towards-web3-native-intelligence-tools-for-protocol-comprehension-and-stewardship/8428/3",
                        "https://www.defieducationfund.org/"
                    ],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "3rd party or author wants to collaborate on proposal"
                    ],
                    "Sentiment": 6.225595238095238
                }
            ]
        }
    ]
}