{
    "poll_list": [],
    "discourse_list": [
        {
            "thread_link": "https://forum.makerdao.com/t/the-endgame-plan-part-3-the-endgame-decentralized-workforce/15737",
            "title": "The Endgame Plan part 3: The Endgame Decentralized Workforce ",
            "index": 15737,
            "category": [
                "Governance"
            ],
            "tags": [
                "longform",
                "endgame"
            ],
            "content": [
                {
                    "author_link": "https://forum.makerdao.com/u/rune",
                    "index": "#1",
                    "likes": "10",
                    "time": "10/06/2022-20:42:09",
                    "content": " image2768\u00d7378 18.2 KB   Part 3: The Endgame Decentralized Workforce The Endgame Decentralized Workforce is an extension of the organically evolved workforce of Core Units and professional delegates that adds a lot of extra elements to the workforce, where each element is designed holistically with the other elements in mind, and where each element fulfils an important high level need (that would otherwise be organically filled in an unstructured and mutable way) so the Decentralized Workforce as a whole can cover all risks and requirements of a robust workforce that can Maker can rely on even decades into the future.  image1920\u00d7981 124 KB   Easy for MKR holders to participate in decisions Making Governance easier and simpler for MKR holders is the number one priority of the Endgame Plan\u2019s approach to the Decentralized Workforce. This includes simplifying governance participation with solutions like Voter Committees and standardized open source frameworks for operational processes and results measurements. The outcome means that it is both easier to follow and understand the state of Maker and its value and risks, but an additional interesting benefit that specifically applies to a DAO is that it also becomes easier for community members to jump right in and contribute to the project with less gatekeeping or onboarding complexity, if they are already able to follow governance.  Focus on dealing with the budget challenge In practice today budget and spending on the decentralized workforce is already the majority of all maker governance work and complexity, and it is a very difficult topic that deals with complicated issues such as compensation, negotiation and human psychology. At the same time Maker Governance is not well equipped to deal with this challenge, as tools related to budgetting are relatively few in contrast to the total amount of MIPs, even if budgetting is the primary challenge facing governance. The Endgame Plan presumes that once certains norms and processes have been put in place and been adopted for a long period, they will ossify and become impossible to change due to familiarity, vested interests and risk aversion. This means that the Endgame Plan needs to deal with not just the budget challenge that exists today, but also the future challenges that will occur, which will be very significant as Maker will run into issues such as overhead growth and capture. Good examples of what this could look like are the defense industry or the american healthcare industry, which suffer from a continuous erosion of efficiency as overhead keeps accumulating over time. The Endgame Plan makes the entire structure of the Decentralized Workforce much more budget focused and \u201cbudget challenge conscious\u201d, in particular by introducing the Budget Allocator Role and the Administrative Core Unit role, both of which help stabilize overhead growth and increases the likelihood of overhead being determined through a fair and free market process, rather than becoming captured.  Separation of powers guaranteed by MetaDAOs The Endgame Decentralized Workforce introduces strict best practice, with the cornerstone being separation of powers. This means that the various roles in the Decentralized Workforce operate independently in a decentralized and free market dynamic, rather than band together as a single group acting as a counterparty to MKR holders. The best practice that need to be in place in order to secure separation of powers over time are enforced by using MetaDAOs and their \u201cresults guarantee\u201d feature create the necessary incentives for a tight feedback loop around strict adherence to best practice. In practice this makes it very easy for MKR holders to take action when best practice has been violated, and MetaDAOs play the role of absorbing the risk of best practice violations.  Public interactions ensure transparency and inclusion One of the key best practice principles of the Endgame Decentralization Workforce that follows from adhering to separation of powers is strict transparency surrounding relationships, negotiations and agreements between the actors in the Decentralized Workforce. This means that all work related communication between different Core Units, or Core Units and Delegates, etc must be either done publicly or be publicly disclosed. This does not apply to intra-core unit communication, since that isn\u2019t necessary if there is enough redundancy and flexibility in the overall structure that allows the system to recover from failure from a single or a few core units.  Open source frameworks used to guide decisions and measure results Another key best practice is that the Endgame Decentralized Workforce works based on pre-written and pre-agreed operational guides and impact measurement frameworks that make things like negotiations and implementation of standard tasks very standardized and uniform. This reduces the possibility of Decentralized workforce making it up as it goes, which also reduces the probability of bus factor and reliance on specific individuals, and as a side effect makes it easier to onboard new Decentralized Workforce participants. The decentralized workforce then simultaneously develops and improves the operational frameworks, while also interpreting and executing in accordance with them. This makes it possible to objectively audit results and adherence to best practice, and makes it possible to compare the work of multiple different Core Units, allowing free market conditions to emerge which makes the Decentralized Workforce much more robust and scalable in the long run.  Understanding the individual roles of the Endgame Decentralized Workforce  image3070\u00d71662 353 KB  At the Maker Governance level, only three roles exist. This helps drastically simplify the core of Maker governance, and improves decentralization because none of the Maker Governance Level roles are \u201cglobally elected\u201d through a MIP, the way Core Units currently are. This means that the power distance between a regular community member and someone who is working for Maker Governance is reduced, which helps with aligning incentives around MKR holders interest. It also makes it less likely that someone would claim to, or be perceived as, \u201crepresenting Maker\u201d, since there is no longer a mechanism of directly electing people or companies through a Maker governance process. All elections are done marginally by joining voter committees, receiving MKR delegation or budget delegation. This means they are relationships between individuals in the Maker Community, rather than relationships between Maker Governance as a whole and individuals (the relationship problem). In general, the three roles at the Maker Governance Levels are designed around the impact of voter incentives on the power and importance of delegates, by focusing on providing checks and balances and clearly limiting the scope of delegates.  Decentralized Voter committees Voter committees have already been covered earlier in this document. They are an open, decentralized role that any MKR holder can participate in. MKR holders that participate in Voter Committees officially, have to link their identity to their MKR, and in return receive small amounts of long term locked MKR as compensation. The Voter Committees are used as a one-stop shop for impactful participation in governance by MKR holders, in particular by setting the direction of governance on specific high level topics (the scope maps), and providing crucial feedback to the Delegates about the perspectives and interests of MKR holders. The Voter Committees aim to ensure that all important high level decisions are always understood by and have received input from regular MKR holders, to minimize the risk that the workforce develops a habit of operating in a closed loop with no input from the community  Delegates Delegates are critical actors in Maker Governance that receive voting power from MKR holders, and in some cases are compensated by the Maker Protocol. There are three types of delegates: Executive Delegates, Recognized Delegates, and Shadow Delegates Shadow Delegates are the fully permissionless and decentralized forms of delegate role, that anyone can become instantly by interacting with the delegation smart contracts. Shadow Delegates are automatically displayed in official voting frontends, but are shown below the other types of delegates. Recognized Delegates are the standard form of Delegates that have proven their identity to Maker Governance as sybil resistance, and have followed certain minimum requirements to become eligible for the role, including filling out forms about their positions on specific governance issues and committing to providing certain updates. Recognized Delegates are compensated with a cash reward that grow proportionally with the amount of MKR they have delegated to them, up to a maximum amount, and depending on their overall ranking amongst all Recognized Delegates. Recognized Delegates have no requirement to attend Voter Committees, but will often use Voter Committees as the place to appeal to MKR holders to get more MKR delegated to them. Recognized Delegates, together with Executive Delegates show up at the top of the official governance frontend in randomized order. Executive Delegates are the Recognized Delegates with the highest amount of MKR delegated to them. There is a fixed number of Executive Delegates spots, defined through a MIP, and they are occupied by the Recognized Delegates with the most MKR delegated to them whenever there is a Executive Delegate election window. They get a fixed compensation based on Facilitator Compensation of the Decentralized Workforce, including a high MKR bonus. Executive Delegates have semi-job security, meaning that they don\u2019t lose their Executive Delegate role even if they fall out of the top list of Recognized Delegates, except if it is during a Executive Delegation election window, or they lose a significant amount of their votes (e.g. more than 50%). This way, the Executive Delegate role becomes competitive with other top leadership roles and will attract the highest quality talent. At the same time Executive Delegates will also have a lot of job requirements, including a weekly minimum hours attendance of legitimate Voter Committees and workforce operational meetings. This means Maker will get a lot more value out of the Executive Delegates, and they can be relied on to play a crucial role at the intersection of MKR holders, the Decentralized Workforce and the Maker Governance process.  Budget Allocators The Budget Allocator (BA) role is a new role that operates between Delegates and Core Units, and is responsible for making marginal adjustments to the operational budgets of Core Units by modifying them based on performance, initiatives and new information. BAs provide an important check on the power of Executive Delegates with Voter Incentives, as they ensure Delegates explicitly aren\u2019t tasked with micromanaging budgets and individual projects, but stay focused on bigger pictures strategy and politics. This makes it much less likely that Delegate politics will backslide into focusing budget towards prestige projects that primarily exist to give the Delegate a political advantage rather than benefit MKR holders.  How Budget Allocators and the Global Allocated Budget works Voters determine the overall amount of the Global Allocated Budget, and individual voters then have the option of delegating Budget Power to the BAs (or let a delegate do it for them, just like with regular voting). The BAs build up budget reserves over time based on their proportional share of the total Allocated Budget, and can then pay it out to Core Unit auditor wallets to fund specific projects. This means that on one hand, the budgeting process for Core Units becomes incredibly flexible as it can be moved around without requiring a cumbersome MKR vote. At the same time, because of the practice of accumulating a budget pool before providing it to a given project, more certainty is also created around projects and budgeting, as Core Units can be provided with the full budget for a large project up front, held in escrow in a way where governance would only ever rescind it in exceptional circumstances (unlike today where governance is at risk of randomly voting down pre-agreed and expected budget extensions which could accidentally tank a project halfway through). Budget Allocators tie into the design of Core Units and the subdivision of Core Units into Administrative Core Units, Contributing Core units and Supporting Core Units. Their roles and differences are explained in further detail below, including more details about how their interact with Budget Allocators. Core Units will have base levels of permanent fixed budget that are determined directly through the MIP framework in the same way as today, but this will only cover lean, baseline operations. The Allocated Budget then adds on top of this guaranteed baseline level of resources.  Minority voter protection Allocated Budget also helps provide minority voter protection, as it moves away from the current paradigm where the majority determines all budgets at all levels, and to one where budgets are determined proportionally based on active votes. E.g. if there is one group with 70% of all active votes, and another group with 30% of all active votes, then in the current paradigm the group with 70% of the active votes will allocate 100% of the budgets, but in the Budget Allocator paradigm the group with 70% of the active votes will allocate 70% of the budgets, while the group with 30% of the active votes will also get to participate and allocate 30% of the budgets.  Budget Allocator Compensation Once they reach a certain size and pass a process to become Recognized, Budget Allocators receive a management fee based on the size of the budget allocated to them, making it a very competitive job that can attract top tier talent for the important task of figuring out how to generate a positive return on Maker expenses.  Baseline Global Allocated Budget Baseline Global Allocated Budget is a way for Maker Governance to specify a \u201chardcoded\u201d Global Allocated Budget using the MIP process, in a process similar to providing a fixed baseline budget to an individual Core Unit.  Relative Global Allocated Budget The most powerful way to use the Budget Allocator paradigm is with the Relative Global Allocated Budget. What this means is that the Global Allocated Budget programmatically scales with the protocol surplus of MakerDAO using a smart contract that is approved through the MIP process. This means MKR holders can ensure that expenses only increase when there\u2019s actually money available to pay for them, and that expenses are automatically scaled down if the protocol\u2019s income starts to dry up, without requiring a frictional political decision.  Relative Global Allocated Budget example Example: Maker Governance votes through 30 million DAI in yearly fixed budgets for the various Core Units to cover all their individual must-have resources and other fundamental needs. An additional 20 million DAI in Baseline Global Allocated Budget is voted in to ensure there is always dry powder available for the BAs to empower CUs to seize opportunities as they become available. Beyond these 50 million DAI of fixed expenses, Maker Governance votes in an additional 100 million DAI of Relative Global Allocated Budget with a \u201cRGAB weight\u201d of 50%. This means that for all protocol surplus beyond the 50 million DAI of fixed expenses, 50% of the surplus goes towards the Global Allocated Budget (calculated on a quarterly basis). Once the Relative Global Allocated Budget cap of 100 million DAI has been reached (which means a total Global Allocated Budget of 120 million when combined with the 20 million DAI of Baseline Global Allocated Budget), 100% of protocol surplus goes towards the standard tokenomics schedule.   Maker Governance votes through a total of 30 million DAI in yearly fixed budgets for the core units to cover all their individual must-have resources and other fundamental needs, through individual MIP-SPs.   An additional 20 million DAI in Baseline Global Allocated Budget is voted in.  This ensures there is always dry powder available for the BAs to empower CUs to seize high value opportunities as they appear.    Beyond these 50 million DAI of fixed expenses, Maker Governance votes in an additional 100 million DAI of Relative Global Allocated Budget (RGAB) with a \u201cRGAB weight\u201d of 50%.  RGAB weight of 50% means that for all protocol surplus beyond the 50 million DAI of fixed expenses, 50% of the surplus goes towards increasing the total Global Allocated Budget (calculated on a quarterly basis).    Once the Relative Global Allocated Budget limit of 100 million DAI has been reached 100% of protocol surplus goes towards the standard tokenomics schedule.  This happens if Maker is earning at least 250 million in income The total Global Allocated Budget that would be available for BA\u2019s to allocate to CU\u2019s would be 120 million (20 million from the Baseline Global Allocated Budget and 100 from the Relative Global Allocated Budget)     Midgame Feature The Budget Allocator role requires an advanced technical system the Endgame Plan does not prioritize this early on. It is instead planned as a Midgame product, which means it is several years out in the future, around the time when budgets could start to get very large and hard to follow. The details of the exact technical specifications of the Budget Allocator infrastructure is provided in the Endgame Plan part 6: The Midgame and Endgame Product List.  image3184\u00d71754 366 KB   DAO2DAO paradigm Maker Core Units are significantly changed in the Endgame Plan, due to the switch to the DAO2DAO paradigm. This change isn\u2019t instant, so the old Core Unit system continues to function, but is slowly and gradually transitioned to the new paradigm, as existing Core Units are reformed and new Core Units are onboarded.  Results Guarantee The first main difference is that Core Units are no longer companies or groups that are hired directly by Maker Governance to receive a budget and do work on a best effort basis. Instead Maker Core Units are a service provided by MetaDAOs to Maker, with the MetaDAO as a whole responsible for delivering certain pre-agreed results and performance targets through an agreement called a Results Guarantee. This includes hiring and supporting the team that practically does the work on a day to day basis, but also means that even if the team stops working or isn\u2019t delivering, the MetaDAO is still responsible for delivering what was agreed. If the MetaDAO fails to deliver the expected results, Maker can claim compensation in the form of a Guarantee Settlement from the MetaDAOs collateral (exactly what makes up MetaDAO collateral and how they get it is explained in later parts of the Endgame Plan). The MetaDAO earns a Guarantee Overhead of 20% on top of the agreed budget for the Core Unit, in exchange for offering the Results Guarantee and taking on the entire risk of failing to meet expectations. This means that MetaDAOs can earn significant profits if they can ensure the Maker Core Units they manage are properly organized and have failsafes in place should something unexpected happen. Meanwhile, Maker has significantly reduced risk from onboarding an retaining Core Units, as long as Maker Governance is able to properly understand and decide between different Results Guarantee and their KPIs or other metrics.  Separation of Powers The second main difference is that Separation of Powers and other best practice requirements are enforced very strictly, and the entire decentralized workforce framework and role breakdown is built around maximizing adherence to Separation of Powers and minimal chance of political breakdown or corruption, even in the very long run. The definition of Separation of Powers is that Core Units and other members of the Decentralized Workforce, such as Delegates and Budget Allocators cannot operate in factions or groups that look out for each others interests, as this would cause political and operational centralization and put their interests at odds with the interests of MKR holders. As a result interactions between Core Units must always be \u201cdecentralized\u201d, meaning they must follow a market process and cannot be biased towards friends or other subjective factors. As bias and factionalism is a natural process of human organization, strict controls and best practice must be in place to prevent it from occuring even over very long time scales, including a zero-exceptions requirement for complete transparency and disclosure of all Maker Governance and Decentralized Workforce work and collaboration beyond the Separation of Powers \u201cFirewalls\u201d. These firewalls include when different Core Units interact with each other, or Core Units and Delegates, or different Delegates etc. In all cases when such an interaction occurs and is work related, it must be recorded or summarized and disclosed through official Maker Communication channels such as the forum or the Governance and Workforce framework tool (described below). The 3 categories of Maker Core Units, and the MetaDAO categories that manage them, are specifically designed to maximize the effect of Separation on Powers on ensuring that it becomes almost impossible for the checks and balances that protects Maker Governance from long term corruption or political breakdown from failing, as long as complete transparency is enforced. Practical examples of how the different types of Core Units interact and how it results in strong Separation of Powers and checks and balances is explained below. Results Guarantee Settlements are likely to often relate to a failure to adhere to Separation of Powers, as being responsible for strict adherence to Separation of Powers is a key task of MetaDAOs and the main incentive that make it possible to implement in real life.  Supporting Core Units (SCUs) Supporting Core Units are managed by Governor MetaDAOs. Supporting Core Units are Core Units that are the least \u201cclose to the action\u201d. Their work is focused on developing open source frameworks that act as operational guides, documentation and knowledge bases within different Scope Maps. They can be compared to an auditing function, that also continuously develops the framework used to run the audits against. As an example, a supporting Core Unit may develop the framework used for collateral onboarding of decentralized collateral. This will include a prioritization system, a step by step guide of the governance and operational process, operational requirements for things like security audits. The collateral onboarding supporting Core Unit also monitors the workforce to track adherence to the framework. In cases where discrepancies are found, the Supporting Core Unit will try to discover the reasons behind the discrepancy. In some cases this will result in new knowledge that is then used to update the framework itself. Supporting Core Units all work together on building the Maker Governance DAO toolkit, which is an open source ERP-like system that is built for all the specific processes required by Maker Governance, to reduce load of procedural information sharing on things like the Maker Forum and to make it possible to easily get a holistic view of the Decentralized Workforce and the state of Maker Governance. The DAO Toolkit integrates all elements of the Decentralized Workforce and Maker Governance, and is specifically designed with a one-size-fits-all approach in relation to both day to day work as well as high level reporting and explanation for Governance in general, and for Decentralized Voter Committees. The goal is to ensure that the \u201clanguage\u201d used by Core Units is as easy to translate as possible as the language used by the Maker community and Decentralized Voter Committees, which both makes it easier to understand what is happening from a governance perspective, but also makes it easier for someone to quickly transitition from a community member and MKR holder to a contributor. Supporting Core Units have fixed budgets from Maker Governance, and can in some cases receive Allocated Budget from the Budget Allocator system, however they do not rely on this and only use it special circumstances.  Administrative Core Units (ACUs) Administrative Core Units are managed by Governor MetaDAOs Administrative Core Units play a role similar to the current intended role of Facilitators in Maker Core Units today. Their job is to directly interface with Maker Governance, and to facilitate and administer the tasks related to a particular area of expertise, budget line item and governance privileges that either cover the entirety of a Scope Map, or a subset of it. Administrative Core Units do not directly perform work for Maker, but instead facilitate that the work gets done in accordance with best practice and with the interests of MKR holders in mind. One very standard task is to negotiate with Contributing Core Units (the core units that do the actual work, and that are similar to the Contributors of current Core Units) and define requirements, milestones, roadmaps and verify the output and security of work product produced by Contributing Core Units. Administrative Core Units are tasked with representing the interests of Maker, and play the role of \u201cproduct owner\u201d. They are trusted to pick contributing core units based on fair and free market competition and negotiate fairly with the interests of MKR holders in mind, and with no bias or conflict on interest when picking the contributors for a particular piece of work. Administrative Core Units are also in charge of prioritizing the work done with the budgets available to them, and must carefully prioritize the work that is most beneficial to Maker. In addition to actively prioritizing and initiating work with their budget, ACUs also reactively facilitate work done through the Maker Governance bounty pipelines, such as collateral onboarding revenue share or feature bounties done by Internal MetaDAO Core Units. ACUs will pay CCUs to do security reviews, and will then make the decision on whether a particular work product fulfill the requirements of a bounty or revenue share, and then use their governance privilieges to put it up to a vote by Maker Governance and issue an advisory recommendation. Administrative Core Units have their own core team that consists of one or more Facilitator that can directly use the Governance privileges available to the ACU as well as supporting staff that consists of experts that can advice the facilitator on what decisions to make. The core team is always paid by a fixed budget paid directly by Maker Governance, and an ACU can never use Allocated Budget to pay for its own expenses. ACUs also have a fixed budget available to pay Contributing Core Units for work within their scope, and in addition often have large amounts of Allocated Budget available to pay CCUs for specific tasks. ACUs work closely with Budget Allocators to plan and finance specific finite tasks. ACUs also contribute to the DAO Toolkit, and provide input to Supporting Core Units that develop the framework they operate within.  Contributing Core Units (CCUs) Contributing Core Units (CCUs) are managed by Creator MetaDAOs. CCUs are the groups that do the actual work in the decentralized workforce, such as execute a marketing strategy, develop a new feature, prepare a collateral onboarding proposal or similar specific tasks that provide some kind of concrete output that has a measurable impact on the value of the Maker Protocol. CCUs are meant to be quite numerous early on in the Endgame Plan and effectively be the backbone of the Decentralized Workforce in the same way legacy Core Units are in the Decentralized Workforce today, but over time they are meant to decrease in quantity and importance and their roles in the ecosystem will be mostly replaced by Internal MetaDAO Core Units as the ecosystem matures and stabilizes. This also means that most CCUs will often naturally transition to become Internal MetaDAO Core Units over time once the incentives start to favour working in that paradigm.  image3274\u00d71736 422 KB  The Decentralized Workforce at the MetaDAO level has roles similar to the Maker level equivalents, and this similarity taps in to the natural synergy of having MetaDAOs reuse as many features as possible for free from Maker, with the freedom to adapt them to its own needs. It also makes it a lot easier for Maker to audit and understand internal governance processes in MetaDAOs, which may be necessary in some dispute situations. Depending on their size and unlike Maker, MetaDAOs don\u2019t have to populate all the roles they have available to safely operate, and in principle a MetaDAO should be able to function without any active Decentralized Workforce structure at all, if necessary, allowing them to operate with no expenses and relying only on token holder governance. As MetaDAOs get larger, they will increasingly be required to populate certain roles in order to fulfill requirements for provable Separation of Powers, to make sure they remain safe as they scale. In practice MetaDAOs will likely populate the roles based on their own incentives in order to be able to properly manage their own complexity and reuse as many lessons from Maker Governance as possible. Unlike Maker, which hires Core Units in the DAO2DAO paradigm, MetaDAOs engage companies directly to provide Core Unit services (the way Maker engages Core Units today), including the MetaDAO Operated Maker Core Unit category which is the MetaDAO level identity of teams that MetaDAOs use to provide DAO2DAO Core Unit services with results guarantee to Maker.  MetaDAO Delegates MetaDAO Delegates have broader authority than their Maker Level counterparts due to the lack of Voter Committees keeping them in check, because disputes within MetaDAOs can be escalated and resolved by Maker Governance. This makes it possible to let MetaDAO delegates have greater control and flexibility without creating political risk, and makes it safe to have less, more powerful MetaDAO delegates.  MetaDAO Budget Allocators MetaDAO BAs can be used once a MetaDAO reaches a very large size, and are very useful for MetaDAOs since they can change and even pivot strategies, which the BA system is well suited to handle in a decentralized setting with reduced risk.  MetaDAO Administrative Core Units (MACUs) MetaDAO Administrative Core Units are the most important Core Unit of a MetaDAO, as they are in charge of day to day operational decision making and budgetting. MetaDAO Administrative Core Units are also responsible for running the internal governance processes of the MetaDAO. They can have multiple focuses and cover many bases, e.g. you could have a MACU for a ReformerDAO both be in charge of Governance, Risk assesment and marketing for the ReformerDAO. In small scale MetaDAO MACU\u2019s can be consolidated, meaning they also perform contributing work and have no separation of Powers, similar to the present Day Core Units. MACUs can in exceptional circumstances provide work to Maker, in case of an unforeseen situation that puts the MetaDAO at risk of missing a projected result which could cause Maker Governance to extract a Guarantee Settlement, and the entire MetaDAO and MetaDAO Decentralized Workforce are responsible for preventing this from occuring.  MetaDAO Operated Maker Core Units (MOMCUs) MOMCUs are Core Units that are hired specifically to provide standing, specialized capacity that can then be offered to Maker as Maker Core Units in DAO2DAO results guarantee agreements. MOMCU\u2019s can also perform work inside the MetaDAO, but only if the MetaDAO is not actively performing DAO2DAO Core Unit services for Maker.  MetaDAO Contributing Core Units (MCCUs) MCCUs are the contributors of MetaDAOs, that do the actual work for a MetaDAO. This can include maintenance of the MetaDAOs internal protocols, or maintenance and research of Maker protocol elements that directly affect the MetaDAO such as its native Singularity Engine. It could also include marketing work or development that benefits the MetaDAO, or Bounty work for a Maker Bounty that the MetaDAO is willing to fund (e.g. a collateral onboarding that is projected to be profitable for the MetaDAO to fund by paying a MCCU to perform the work)  Ecosystem Actors (EAs) EAs are not directly a part of the MetaDAO Decentralized Workforce, but are very adjacent to it and directly interact with it. EAs are counterparties like Node Network Operators, RWA Arrangers, security auditors, marketing agencies, freelance developers, consultants etc. They interact with MetaDAOs through the MACUs or MCCUs (depending on the type of EA) and can indirectly interact with Maker, with the MetaDAO and its governance infrastructure as the intermediary (such as in the example of RWA arrangers that ultimately are funded through a Maker D3M). EAs are paid in cash only and do not receive MKR or MetaDAO tokens as additional compensation.  The Endgame Decentralized Workforce in practice To provide an example of how the different roles in the Decentralized Workforce at the Maker and MetaDAO levels work together at the long run equilibrium of the Endgame Plan, we will consider the 3 most common long run scenarios. These situations all concern \u201cRecurring expansion work\u201d which is predefined work that Maker will need to continue doing perpetually in order to grow and optimize itself. This includes tasks such as collateral onboarding, synthetic asset deployment, sharded vault engine deployment on new blockchains or L2s, governance submodule (e.g. IAM) deployment, gas efficiency upgrades, security upgrades, security fixes etc The three approaches to long run Recurring Expansion Work are: Classic Top Down, Bottom Up With Revenue Share, and D3M Model  image3364\u00d71766 443 KB  The first scenario is the Classic Top Down scenario which is very similar to how the Decentralized Workforce does work today, extended with very strong checks and balances and feedback loops. The Classic Top Down scenarios begins with the Facilitator of an ACU making a decision to prioritize and spend budget on a specific task. The ACU (managed by a GovernorDAO) then engages one or more CCUs (Managed by separate CreatorDAOs) to gather quotes and work estimates. After gathering information, the ACU facilitator makes a decision and engages the CCU to do the work, and begins paying out the agreed budget. After the work is done, the CCU delivers the finished work to the ACU, which reviews it and in some cases engages an EA or another, independent CCU to do a final review. If the review is passed, the ACU uses its governance privilege to bring the work to Maker Governance, usually through a governance proposal, or through a public review if a governance proposal isn\u2019t necessary (e.g. the work done was offchain work or documentation work or similar). When the work is done the budget is spent and the interaction is over from the perspective of the Core Units, who will move on to other tasks and have no further connection to the task they just completed. They have been paid up front in cash and have no positive exposure to the outcome they\u2019ve created. Supporting Core Units are tasked with monitoring the interactions and the outputs of the work done by the ACU\u2019s and CCU\u2019s, and if they find something that seems out of place, such as not following best practice, they flag it to a voter committee. The voter committee may decide to look further into it, and may request the SCU to provide a presentation of the problem. If the voter committee determines the problem has breached the results guarantee of the involved MetaDAOs, they will then consider proposals and who and how much to extract in a Guarantee Settlement. This dynamic means that the internal governance of MetaDAOs is heavily focused on ensuring the Maker Core Units that they manage and provide Results Guarantee services for are run extremely well, and are always looking out for the perspective of MKR holders and voter committees, learning from actions and decisions made with regard to other MetaDAOs. The downside of the approach is that it still requires significant resources from Maker Governance, including Supporting Core Units performing advanced monitoring and DVCs intervening to the extent where the threat of intervention is a realistic driver of MetaDAO behaviour.  image1920\u00d7989 96.6 KB  The second standard form of work in the DAO2DAO paradigm is the Bottom up with revenue share approach. In this approach Supporting Core Units develop and propose bounty frameworks that are ratified by Maker Governance. Once the bounty frameworks are active, MetaDAO Administrative Core Units now have an incentive to spend budget on MetaDAO Contributing Core Units (MCCU\u2019s) to work on these bounties, such as onboarding collateral specified by the bounty framework. When the MCCU\u2019s finish their work they deliver it directly a Maker level Administrative Core Unit (ACU), who performs a security review (possibly with input from an ecosystem actor or a CCU). If the security review passes, the ACU proposes the work product to Maker Governance, with a revenue share model specified that is in accordance with the bounty framework. The CreatorDAO then earns a large temporary revenue share from adoption of the work product. Maker only needs to spend relatively little budget on this approach, as most of the work and risk is done internally in the MetaDAO, in particular the risk of selecting promising collateral to onboard. E.g. If a MetaDAO onboards a collateral asset that turns out to not be in demand by vault users, Maker spends almost no resources while the MetaDAO pays for all expenses and also gains no upside since its upside comes in the form of a revenue share. This aligns incentives strongly and means MetaDAOs have to very carefully decide to only do work that will actually provide good results and outcomes. As a result, supporting Core Units and Voter Committees don\u2019t have to do much work since it is rare that Maker will lose, even when bad decisions are made, since Maker is generally not paying any expenses or taking any risk. In the long run this is preferable to the classic top down approach, whenever possible, as it is more scalable, parallelizable and less risky.  image3400\u00d71838 458 KB  The third and most scalable approach to work in the MetaDAO paradigm is to simply rely on D3M modules to wholesale fund MetaDAO activities. This means that Maker is not involved in any synchronous step of the active work, such as taking exposure to assets or onboarding vault collateral. The MetaDAO is simply provided a global debt ceiling by Maker, and pays a specific cost of capital, and can then freely decide what to do with it using its internal resources, following the basic separation of powers flow where MetaDAO Administrative Core Units (MACUs) prioritize and spend budget, MetaDAO Contributing Core Units (MCCUs) do the work, and MACUs then review, approve and propose the final work product to a MetaDAO governance vote. At the Maker Governance level, the only interactions are long term periodic reviews of the performance of each MetaDAO D3M, allowing Maker to tap into the synergy of MetaDAOs using similar internal governance structures, tools and frameworks to efficiently review their performance and risk. This the optimal way for Maker Governance to function, since it can operate at its natural, very slow pace, and review relative data rather than trying to find absolute truth. The main question becomes, \u201cwhich MetaDAO(s) has done the best job during the last period?\u201d, and if then rebalancing debt ceiling from the worse performers towards the better performs. This then rebalances Makers risk and return, and also creates a strong evolutionary feedback loop where MetaDAOs are incentivized to learn from each other and adopt best practices that organically emerge. In all cases where the D3M Model is used, Maker has limited protection from losses by the entirety of the MetaDAOs assets and MetaDAO tokens as credit-enhancing collateral.  image1920\u00d71094 103 KB  The Endgame Decentralized Workforce is required to coordinate all of its work, and share all of its information, through a single universal DAO Toolkit that is specifically designed to efficiently implement the processes that Maker needs to operate with in the long term equilibrium of the Endgame plan. This includes both kanban like features for Core Units to manage and track work deliverables, but also MIP tracking and overview, financial review and many specific tasks and processes that relate to different Scope Maps, such as collateral onboarding specific data visualization. In order to achieve the goal of the Endgame Decentralized Workforce, which is to make it as easy as possible for MKR holders to follow and contribute to the work being done, the universal DAO Toolkit doesn\u2019t only serve as an operational toolkit, it also serves as the primary governance information toolkit. In general, everything that needs a system, or a dashboard or similar, must be unified into the universal DAO Toolkit, so it is as easy as possible to find and review everything, and so that a shared language and symbolism is used across the board, reducing information cost.  Universal Dao Toolkit synergy with MetaDAO paradigm There is a strong synergy with the MetaDAO paradigm, insofar their similarities with MakerDAO means that the universal DAO Toolkit can also be adopted and effectively used by them, but with the benefit that they can freely extend or modify it as they need based on the direction of their growth. The Universal DAO Toolkit also helps simplify what it takes to create a fully functional MetaDAO, since that will at its core involve deploying a token and then deploying a new unique instance ",
                    "links": [
                        "https://forum.makerdao.com/t/forum-at-a-glance-june-09-15-2022/15843",
                        "https://forum.makerdao.com/t/relay-semanal-21-27-de-junio-del-2022/16272",
                        "https://forum.makerdao.com/t/un-vistazo-al-foro-16-22-de-junio-del-2022/16204",
                        "https://forum.makerdao.com/t/weekly-relay-june-21-27-2022/16158",
                        "https://forum.makerdao.com/t/relay-semanal-14-20-de-junio-del-2022/16062",
                        "https://forum.makerdao.com/t/endgame-index-list/16021",
                        "https://forum.makerdao.com/t/forum-at-a-glance-june-16-22-2022/15999",
                        "https://forum.makerdao.com/t/el-plan-endgame-parte-3-la-fuerza-de-trabajo-descentralizada-de-endgame-traduccion/15988",
                        "https://forum.makerdao.com/t/un-vistazo-al-foro-09-15-de-junio-de-2022/15954",
                        "https://forum.makerdao.com/t/weekly-relay-june-14-20-2022/15950",
                        "https://forum.makerdao.com/t/weekly-relay-june-7-13-2022/15818",
                        "https://forum.makerdao.com/t/relay-semanal-7-13-de-junio-2022/15897"
                    ],
                    "GPT-summary": null,
                    "GPT-proposal-categories": null,
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.614533782855987
                },
                {
                    "author_link": "https://forum.makerdao.com/u/CodeKnight",
                    "index": "#2",
                    "likes": "0",
                    "time": "10/06/2022-21:21:22",
                    "content": "So is the expectation that CUs will subcontract all work beyond their fixed budget? Seeing as they can\u2019t rely on it, they would need to  be able to quickly cut that extra spending very quickly. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.366666666666667
                },
                {
                    "author_link": "https://forum.makerdao.com/u/rune",
                    "index": "#3",
                    "likes": "2",
                    "time": "10/06/2022-21:30:24",
                    "content": "To a certain extent yes, since the entire dynamic of ACUs and CCUs is based around this interaction (a free market competitive subcontracting economy), and specifically it would be administrative core units getting budget and tasks from budget allocators and then subcontracting it out to contributing core units and ecosystem actors. The ability to scale headcount up and down relies on the ability of the broader metaDAO talent pool to be very flexible in accommodating talent. So basically creator DAOs will benefit from being set up to use their talent for other things if they aren\u2019t being utilized by maker. Finally, some allocated budget can be relied on, to a certain extent, just like core units rely on renewing budgets today even though it isn\u2019t a given. It\u2019s just the metaDAOs, specifically the creatorDAOs that ultimately take the risk of relying on it (but they also get to earn a premium for taking on that risk). One thing I also am still working on is how to apply MKR bonuses. It\u2019s possible maker would commit to certain MKR bonuses that would be more reliable than the allocated budget, but how exactly to determine which individuals are eligible for it isn\u2019t clear yet ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.6041005291005295
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Matt_NZ",
                    "index": "#4",
                    "likes": "6",
                    "time": "02/07/2022-08:11:49",
                    "content": "    rune:  Making Governance easier and simpler for MKR holders is the number one priority of the Endgame Plan\u2019s approach to the Decentralized Workforce. This includes simplifying governance participation with solutions like Voter Committees and standardized open source frameworks for operational processes and results measurements.   I\u2019m re-reading the Endgame documentation to get my head around it and this seems like a crucial piece of the puzzle. If Maker can make governance easier and simpler, that\u2019d be a fantastic result. In practice though I worry the new governance mechanics around voter committees will make the system more complicated and politicised, rather than less.   Aren\u2019t voter committees in their future, decentralised state just going to be another venue for political conflict and disharmony? Why will they be able to cohesively \u201cset the direction of governance\u201d when there is so little consensus on that as is?   What happens in the inevitable event there is disagreement about the composition of voter committees? Who settles those disputes?   I also note that voter committees are charged with investigating poor work by MetaDAOs, determining whether the MetaDAO has breached their results guarantee, and then negotiating a settlement. How will ordinary MKR holders on voter committees well placed to do any of these things\u2026? This also introduces other issues too if the voter committees are not well compensated - like MetaDAOs being incentivised to bribe committee members to make a finding in their favour.   The system seems more decentralised, but it also seems much more political, while also handing important decisions over to committees that do not seem well placed to answer the difficult and polarising questions they will be asked. Let me know if I\u2019m missing something in my thoughts above @rune. ",
                    "links": [
                        "https://forum.makerdao.com/t/frontier-research-delegate-platform/17298"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.137999311294765
                },
                {
                    "author_link": "https://forum.makerdao.com/u/monkey.irish",
                    "index": "#5",
                    "likes": "9",
                    "time": "21/07/2022-02:09:15",
                    "content": "    rune:     @rune I liken the end game to kernel and user space. Here is a pretty good definition of it: Kernel space and user space is the separation of the privileged operating system functions and the restricted user applications. The separation is necessary to prevent user applications from ransacking your computer. My curiosity is around control points and what needs to be ossified. Generally speaking, the kernel space (core Maker protocol and governance) are candidates for thoughtful evolution, innovation, and selective ossification. The user space (MetaDAOs, etc.), is where all the boring to insane stuff happens. If the interfaces are developed and implemented correctly, separation between kernel and user spaces maintains the system integrity. At this moment, I have a few observations about the end game plan. I share this as I\u2019ve been trying to formulate an approach for CES. In part three of the end game plan, there are the Maker and MetaDAO Levels. This is the obvious place for separation of the kernel and user spaces. I think the Maker Level has room of simplification but that is part of another discussion. The interfaces between the Maker and MetaDAO Levels is where the accountability, funding, incentives, and tokenomics are present. Those are control points and need to be carefully designed and implemented. If done correctly, I think the end game job is complete. The label \u201cMetaDAO\u201d is a black box construct. It is user space. Put something in, get something out. It can\u2019t break anything. Why extend all of the Maker Level constructs into the MetaDAO? If the interfaces (and incentives) are developed correctly, the user space will respond in the desired way. If the tokenomics work, I\u2019m all over it. If there is an incentive to run an oracle, I\u2019m in. I think you get the point. In my opinion, there is a considerable amount of time being spent on things that we do not want to try to control e.g. what is a MetaDAO. CES could become a MetaDAO tomorrow. We do not need any of the overhead that is being proposed on the MetaDAO Level to complete our work. I\u2019m not criticizing it\u2026I just don\u2019t need it to run a business. What I need is autonomy and to ensure my KPIs are set correctly so I can deliver what has been mutually agreed. That\u2019s it. And my budget of course\u2026  When the interfaces (tokenomics, etc.) are developed and present, either they will be attractive and I will act accordingly or I\u2019ll ignore them. Trying to enforce constructs from the Maker Level onto the MetaDAO Level is a futile exercise. I would prefer for the MetaDAOs to be completely market driven. It removes control points and any responsibility of the core MakerDAO from the equation. I highly encourage you to consider drawing the end game line at the interfaces between the Maker and MetaDAO Levels. I think it\u2019s less complex and also more supportive of your Simple Dai thoughts. I also see this approach as potentially doing both Simple Dai and MetaDAOs at the same time. Thanks for your consideration. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 4.895495495495496
                },
                {
                    "author_link": "https://forum.makerdao.com/u/rspa",
                    "index": "#6",
                    "likes": "0",
                    "time": "22/07/2022-12:22:51",
                    "content": "    monkey.irish:  I would prefer for the MetaDAOs to be completely market driven   MetaDAOs and Maker Core (SimpleDAI) are well seperated. But Maker Core can enforce some performance guarantees and make sure the MetaDAOs deliver, while also bootstrapping them with talent and cash. Do you feel that it would be better if MetaDAOs aren\u2019t born out of Maker at all but instead attach themselves to Maker from the outside? I think this could also happen. The Endgame Plan offers an opportunity for the existing talent of Maker to migrate to a place where they are not hindered by risk-averse governance (necessarily risk-averse, it\u2019s a stablecoin) and where they can reach maximum utility. The other approach would be to cut all but Maker Core, pay some severance and basically say: \u201cGood luck on the open market and please think of us when you make money\u2026\u201d ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.9375
                },
                {
                    "author_link": "https://forum.makerdao.com/u/adcv",
                    "index": "#7",
                    "likes": "5",
                    "time": "22/07/2022-12:31:49",
                    "content": "    rspa:  The other approach would be to cut all but Maker Core, pay some severance and basically say: \u201cGood luck on the open market and please think of us when you make money\u2026\u201d   This cannot possibly be the only alternative to spinning up 20 MetaDAOs and their corresponding ICOs imo. Understand the desire to leverage market forces but this doesn\u2019t really solve adverse selection and introduces an important illiquidity factor that risks dragging MKR price. An alternative could be to take the pragmatic view from the status quo, fence off riskier tranches of capital in MetaDAOs (without tokens) with their own stDAI junior loss absorbing equity, reward Core Units that take steps to ossify governance and remove themselves from the equation and over time remove the workforce completely, ideally. You could do that starting from today, if MKR holders wanted to. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.306818181818182
                },
                {
                    "author_link": "https://forum.makerdao.com/u/monkey.irish",
                    "index": "#8",
                    "likes": "4",
                    "time": "22/07/2022-15:58:27",
                    "content": "The separation has been identified so that is the first step. Continuing with my technical example\u2026if the two had to communicate via APIs, what would those definitions look like? Those are the interfaces I am talking about: funding, KPIs, accountability, tokenomics, etc. The Maker Level defines the operation of those interfaces/APIs. CRUD operations and state changes can occur by the clients (MetaDAO Level). My opinion is to have the End Game focus on the Maker Level and interfaces. To push or enforce Maker Level structures and constructs onto the MetaDAOs is a misuse of applicability, time, and energy. We are saying MetaDAOs are autonomous but then we also say they need to work a certain way. That is confusing to me. What would be the concern if a specific MetaDAO was really a centralized organization? If any MetaDAO is going to truly handle RWAs, it\u2019s going to be a Swiss or Cayman org. What if a MetaDAO is only partially decentralized? Will the purists say, no way, MetaDAOs MUST look like X? I do not think the Maker Level needs to be concerned at all about these types of issues. This is what I refer to as market driven. Now, if the Maker Level wants to provide frameworks and toolkits for those less experienced in running a business, sure, that might be useful. Right now, the bias must be towards experimentation and action. For CES, I am looking to do bullet three asap. As the interfaces are experimented with, built, and compelling, we\u2019ll adopt them. I highly encourage the End Game community to focus on building the Maker Level and compelling/market driven interfaces to attract not only the current CUs but also a wider variety of other entities that have the ability to add value to the Maker protocol. Provide guidance and suggestions to the MetaDAOs but do not enforce anything. Attract and convince market participants by the quality of the interfaces. Otherwise, we\u2019ll have a captive audience of marginal players.  Screen Shot 2022-07-21 at 1.23.06 PM1896\u00d71094 110 KB  ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.503819444444444
                },
                {
                    "author_link": "https://forum.makerdao.com/u/rspa",
                    "index": "#9",
                    "likes": "0",
                    "time": "25/07/2022-11:45:55",
                    "content": "    adcv:  This cannot possibly be the only alternative to spinning up 20 MetaDAOs   6 initial MetaDAOs are the start\u2026 After that, it\u2019s governed by supply and demand. The one problem endgame solves uniquely is org complexity and scaling in decentralised organisations. Most proposals seem to think of the DAO as a kind of company-in-formation. But Maker should not go that route in my opinion. We know how to scale centralised orgs. But that doesn\u2019t mean we cannot develop scaling solutions for decentralized organisations. How do you build something that can scale without ever breaking down or reverting to centralised leadership, simply because this is how we\u2019ve done it in the past. And quite frankly, I have yet to see a convincing proposal that accounts for that, other than the endgame. Does it mean it will work? No, there\u2019s a chance it might not work\u2026 But I agree that the only other way is to keep things small. Because small decentralised organisations work, and SimpleDAI could be automated to a large degree, which makes the regulatory attack surface quite small if current regimes offer any guidance. I always respect your opinion. And I like the approach you\u2019re presenting, but I think it doesn\u2019t solve some of the core challenges of DAOs at scale. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0396825396825395
                },
                {
                    "author_link": "https://forum.makerdao.com/u/adcv",
                    "index": "#10",
                    "likes": "3",
                    "time": "25/07/2022-12:18:02",
                    "content": "    rspa:  I always respect your opinion. And I like the approach you\u2019re presenting, but I think it doesn\u2019t solve some of the core challenges of DAOs at scale.   I appreciate the thought, though would also welcome some more color on why specifically you believe Endgame MetaDAOs are the only or most appropriate solution to scale decentralized organizations. To be clear I don\u2019t think we are far off. To my mind, pushing out complexity to the edges is good and is suitable for a protocol that should be able to scale almost infinitely with very little additional overhead. This unified toolkit is an obvious improvement on the status quo. And so forth. However, I also believe pushing out complexity at the same time as removing direct accountability (which MetaDAOs do by design by depending on token interfaces and market forces for eg) is not good. I believe it risks worsening adverse selection problems Maker already faces and could create warring Taifas instead of a community concerned about managing the protocol judiciously on behalf of Dai holders and vault users. Many of the arguments I am seeing for all of the complex features of the Endgame Plan seem like just affirmations of faith rather than reasoning why specific mechanics are suitable for tackling specific problems. Without even getting into some of the adjacent products or yield farming. Why have a unified toolkit at all if the MetaDAOs are supposed to be operating autonomously? idk maybe I just don\u2019t see it yet. I tend to rely on straightforward heuristics for evaluating ideas like this as a first cut, maybe naively. I believe organizational plans very very rarely survive even 1 \u2018block\u2019 of real-world contact. Likelihood of success improves the simpler the plan is from the outset. Building a hyperstructured complex game ex-nihilo then pressing play makes the path to success as planned very narrow imo. Especially when the protocol is in motion already. Indulge my strategy gamer hat for a second. You can run a clean start build on SimCity 3000 with the money cheat, lay out the grid for miles, build out every possible infrastructure need you think your citizens will have. It will look great. Then you press Play and watch it quickly snarl into unpredictable patterns and massive dysfunction compounded by the fact that to unwind and try an iterative approach (move a hospital from here to there) you have to demolish most of the expensive structures you put in place. Forget running at a surplus - this is a recipe for never having a city at all. Now imagine doing the same but without a money cheat and with a city already laid out. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.804217479674797
                },
                {
                    "author_link": "https://forum.makerdao.com/u/rspa",
                    "index": "#11",
                    "likes": "2",
                    "time": "25/07/2022-13:40:01",
                    "content": "    adcv:  with the money cheat   I always used that  but on the original Sim City, worked out really well\u2026 But I\u2019m digressing.     adcv:  Why have a unified toolkit at all if the MetaDAOs are supposed to be operating autonomously?   All I am seeing is a tokenomics system that ties MetaDAOs to Maker Core. And a code-base to use, if applicable, Apart from that, all the blueprints are that MetaDAOs can use Maker governance for arbitration and are formed out of the DAO whenever a certain field of activity is becoming sufficiently alive to form a MetaDAO. This way complexity is always pushed out of the core. I guess we agree there. Apart from that, at least the way I see it, we are currently engaged in building the endgame plan. That means that anything that will not work needs to be addressed as soon as we recognize it. We can see that a lot of thought went into the design, but I think now is a very good time to address challenges constructively.     adcv:  at the same time as removing direct accountability   This is feature, in my opinion. It allows for specialization and MetaDAOs have performance guarantees, which ultimately is all that matters for MKR holders. Other than that, it allows those with the interest and bandwidth to focus on specific issues by being active in the MetaDAOs instead of the current, all-encompassing approach.     adcv:  just affirmations of faith rather than reasoning why specific mechanics are suitable for tackling specific problems.   A lot of the details are just now being discussed. Rather than affirmations of faith, I see it as active interest and participation in developing this to a point where it actually works. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.620861678004535
                },
                {
                    "author_link": "https://forum.makerdao.com/u/rune",
                    "index": "#12",
                    "likes": "3",
                    "time": "27/07/2022-15:25:40",
                    "content": "Hey Robert, thanks for the post. Finally I have some time to reply to it. There\u2019s also been a lot of other recent replies in Endgame related threads, but I haven\u2019t been able to comment on most of them, so I plan to talk about these subjects on todays Endgame DVC meeting in a few hours. I\u2019ll try to break it down to some smaller points and answer them:  Why should Maker Governance/The Endgame Plan define what the internal structure of a MetaDAO looks like at genesis?  The short answer is that no one else can. MetaDAOs are born decentralized, so before they are created there is no founding team, starting principles, white paper etc that goes beyond the standard \u201cMetaDAO blueprint\u201d. This ensures that no MetaDAO tokens have to be \u201cpremined\u201d to individuals, and that there are no one who plays with a special ruleset when it comes to influencing and defining the new metaverse of the fresh MetaDAO. I believe maintaining integrity in this respect is essential in order to maximize the value of the final metaverse and the strength and independence of the community of the MetaDAO itself. Any speck of centralization or bias in a new MetaDAO will become seeds of dysfunction that will culturally echo forever. Without an insider group, a new MetaDAO is a true blank slate where all participants are treated fairly when contributing to the development of the new metaverse. This will make it a lot easier for participants to commit to whatever the outcome is, because the process itself was transparent and understood in advance, and played out fairly according its rules, so there is nothing to reopen. Having a strong, aligned and coherent community is essential to a successful DAO, because the strength of the community (the \u201cspark\u201d), determines how much semi-altruistic behaviour to expect from individuals in the community, and this in term determines how complex governance levers the community can handle. Semi-altruism is when community members do things like spread the word about the DAOs products, or participate in a governance processes. These are actions that in isolation do not benefit the individual taking the action, but the group as a whole benefits, so the individual is motivated due to their membership in the group. Spark is particularly crucial when it comes to fighting corruption and maintaining decentralization in the governance process by being willing to take action when critical problems are found. Spark is also essential to achieving viral growth of a community, and viral growth is one of the fundamental avenues we must use if we want to make a dent in the dangerously broken global financial system.  Why does Maker Governance care about what the inner workings of a MetaDAO looks like?  The main reason is because MetaDAOs still have to be actual DAOs, meaning they must have political and operational decentralization. This minimizes the chance that the MetaDAO corrupts or centralizes over time, and it means the MetaDAO becomes a source of viral growth and generates an extremely valuable, sticky \u201cdeep community\u201d. In general, without decentralization, MetaDAOs make no sense and can\u2019t even technically exist (as MetaDAOs - since a centralized DAO is just a general partnership, no reason to give it a new name), and also has no unique value to Maker beyond any other company or individual. Maintaining decentralization must be enforced internally in the MetaDAO in the same way it must be done in Maker, by having token holders with enough spark to be able to actually participate in the governance process, while also have low enough information cost to be able to make useful decisions, in particular regarding risks of corruption and centralization. Both of these requirements IMO speaks to using a simplified copy of the basic structure of Maker governance as the starting point for all MetaDAOs, with no exceptions. In general of course, there should be lower standards and more room for error, since MetaDAOs, unlike Maker, can recover if they spiral down the centralization or corruption failure modes. I also think it makes sense to allow MetaDAOs to change their governance structure over time, but I think it will always need to remain similar to Maker and other MetaDAOs, so that it is always easy to detect signs of corruption or centralization from the Maker level, and so that interoperability and workforce fluidity is maximized across the MetaDAO ecosystem.  Whatever \u201cinterfaces\u201d that are available to MetaDAOs should also be available to other organizations  I totally agree. Thinking of it as a kernel/user space and a set of interfaces is a great way to help make the endgame state more concrete. While I don\u2019t think this changes the value and need for born-decentralized MetaDAOs, making sure that the market they operate in is as open and accessible as possible is just another dimension of efficiency and opportunity that Maker can harness with minimal cost and significant upside. I define everything that is not Maker or MetaDAOs as Ecosystem Actors, and they can really be anything, including DAOs, companies or individuals. The same opportunties that are available to MetaDAOs, should also be available more generally to ecosystem actors, as long as they follow the same standards and provide the same protections. There are already several systems described in the Endgame Plan that I think cover this \u201cinterface\u201d approach quite well, and I\u2019ll summarize some of them: Frontend Rev Share All Metadaos revolve around their frontends which they use to attract users and community members. The cornerstone of the frontend business model is the net stability fee rev share on Maker Vaults, which gives the metaDAOs a fixed % of what maker earns on stability fees (with DSR subtracted) that are managed through the metaDAOs frontend. So as an example, if a metaDAO runs a frontend that has 100 million of outstanding vault debt, paying 3% in stability fees with DSR at 0% and the net rev share at 20%, then the metaDAO earns 600k dai per year paid out - and this income is completely risk free and governance free, all it requires is that the metaDAO attract the customers. The practicality of paying the rev share can be calculated off chain and transferred manually at a fixed interval. This same model works just as well for private companies, and should also be made available to oasis, DeFi saver, instadapp, and if we see success stories where the income makes a difference for them, then we should expect more vault frontends due to the profit signal. Protocol upgrade with temporary rev share In the endgame, rather than maker organizing all protocol expansion through top down budget allocation that\u2019s very vulnerable to corruption and politics, the temporary rev share model is a lot more decentralized and low risk.  image3424\u00d71796 510 KB  Basically Maker Governance (with input from Councils) specifies a revenue share bounty framework, and if a MetaDAO does all the work related to onboarding a new collateral type and, it conforms to the framework and is accepted by Maker Governance, then the MetaDAO will receive a large temporary revenue share of all net stability fees earned from the new vault. This could be e.g. 30% for 10 years. This process can also work for bigger and more important things, such as deploying an entire sharded vault engine or even a primary vault engine for a new synthetic asset, and each different eligible type of upgrade would have a specification for its revenue share or fixed bounty. Of course this option should also be available to Ecosystem Actors, and should function the same way where an Ecosystem Actor does all the work according to the framework that defines the interface and then delivers it to a Core Unit, which can then choose to review it and present it to Maker Governance, and if passed the Ecosystem Actor that gets the revenue share sent straight to whatever Ethereum account they choose, regardless of whether it is a company, person or DAO. Plug and Play Protocols Plug and Play Protocols is a new concept that applies to the MetaDAO ecosystem itself - the idea is that any open source code for DeFi smart contracts can be built to enable instant deployment and use by MetaDAOs (\u201cPlug and Play\u201d), and this kind of development should be encouraged by allowing creators of such useful code to monetize it with a revenue share percentage. The process is super easy and available to anyone, all it requires is a standardized process for making Plug and Play Protocol code available, and a standard format for specifying terms such as revenue share and minimum fees. Maker Governance can then automatically enforce these revenue shares by virtue of having direct governance control over the MetaDAOs. I think this could be a really exciting frontier of open source software, since it seems to deliver the holy grail by making it possible to both develop software completely in the open, but at the same time be able to easily and safely monetize it with no need for contracts or even any kind of human interaction. Both MetaDAOs and Ecosystem Actors can develop Plug and Play Protocols and make them available for MetaDAOs to use with a Maker Governance enforced rev share percentage. If we can prove that there is money to be made in building these, and that it\u2019s a fair and free market where everyone plays by the same, predictable rules, then we could see a rush of new businesses that specialize in working in this field - especially since they can also make their products available elsewhere and monetize them e.g. in their own frontends.  Why should MetaDAOs be forced to use a particular arbitrary tokenomics system  I will write a lot more about this in both part 8 and part 9 of the endgame plan, but let me just quickly summarize my hypothesis on tokenomics. Tokenomics have two types of users, rational actors and regular humans. Rational actors generally don\u2019t care what shape your tokenomics have, they just care about how much income is generated and how much it is used for the benefit of the token holders. They will basically just do the math and reduce any tokenomics system into a dividend flow or similar, so they don\u2019t care what form it takes as long as its not wasting money or providing selective benefit to special interests. But for regular humans, the specific type of tokenomics that delivers value to them matters as much, if not more, than the underlying fundamentals. This is the intangible value that is created from the gamification effect of having interesting tokenomics. So on balance, there is no downside but plenty of upside when it comes to regular people, which are by far the biggest group of users and holders of crypto in general and also DeFi tokens. So this argues why we should have advanced, gamified tokenomics, but why should all the MetaDAOs use the same system, why can\u2019t they innovate? The answer is that the tokenomics themselves are what aligns Maker and the MetaDAOs interests, due to how intricately they are entangled, so it is crucial that they are all treated exactly the same in order to create a fair playing field and also prevent changes or additional exceptions. There\u2019s also a final point about the tokenomics I want to make, which is how they contribute to complexity ossification. Basically the tokenomics are so advanced, with so many second and third order effects, that they can\u2019t reasonably be simulated or \u201csolved\u201d, and this means that it will be much harder, near impossible, to attempt to change them with full consensus since everyone will have different personal opinions about what they think makes them better or worse off - which is a good thing because ossification in one place helps promote ossification elsewhere. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.7004417094533375
                },
                {
                    "author_link": "https://forum.makerdao.com/u/monkey.irish",
                    "index": "#13",
                    "likes": "1",
                    "time": "27/07/2022-16:47:25",
                    "content": "    rune:  I define everything that is not Maker or MetaDAOs as Ecosystem Actors, and they can really be anything, including DAOs, companies or individuals. The same opportunties that are available to MetaDAOs, should also be available more generally to ecosystem actors, as long as they follow the same standards and provide the same protections.   Thanks for the detailed reply. This is helpful in understanding your thoughts around the MetaDAOs. If the End Game is about enforcing the same structure at the Maker and Meta DAO level, it\u2019s probably best that I reposition my efforts as an Ecosystem Actor. As additional details emerge about MetaDAOs, I\u2019ll continue to evaluate it as we go through the transition process. My focus is on execution and adding value. I am looking for the best structure that allows us to do that asap while maintaining strategic positioning for the future. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.15625
                },
                {
                    "author_link": "https://forum.makerdao.com/u/system",
                    "index": "#14",
                    "likes": "0",
                    "time": "26/10/2022-22:47:33",
                    "content": "This topic was automatically closed 91 days after the last reply. New replies are no longer allowed. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0606060606060606
                }
            ]
        }
    ]
}