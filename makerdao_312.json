{
    "poll_list": [],
    "discourse_list": [
        {
            "thread_link": "https://forum.makerdao.com/t/possible-data-source-for-determining-compensation/1155",
            "title": "Possible data source for determining compensation ",
            "index": 1155,
            "category": [
                "Discontinued Categories",
                "Misc Discontinued"
            ],
            "tags": [
                "analysis",
                "data",
                "payroll",
                "sourcecred"
            ],
            "content": [
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#1",
                    "likes": "10",
                    "time": "21/01/2020-01:38:24",
                    "content": "Long time Maker watcher, first time poster. Have been following recent discussions around Maker governance overhead and how to compensate workers. Coming up with a fair, decentralized way to quantify value (and pay people), is of course a giant, unsolved problem, and necessary feature for a truly decentralized treasury. Recently, I\u2019ve been contributing to an OSS project (SourceCred) that is building a reputation protocol. I\u2019m wondering if it might be an interesting data source. The core of the protocol is a modified PageRank algorithm (what Google is based on), which itself was modeled after citations in academic publishing (a model @rune and others have suggested exploring). I\u2019m not sure how it would fit into the Risk Governance Framework, but it does work on Discourse forums (a place where governance work takes place), so I\u2019ve run it on the MakerDAO Discourse for fun. Curious to see if the scores make intuitive sense to regular posters here.  image1060\u00d7706 99.6 KB  A hosted instance of above can be found here, if you want to play with the weights for different variables. I\u2019ve also run it on the \u2018mcd-cdp-portal\u2019 repo to see if it makes sense for scoring developers.  image1078\u00d7707 111 KB  A hosted instance can be found here. For code, if you click the \u2018legacy\u2019 link in the upper left corner, you can drill down and see a breakdown of what contributions generated reputation points. Full disclosure: SourceCred is paying contributors according to their cred scores, currently about $15k/week. If I link to this on the SourceCred Discord and people reply and/or , I may get paid some    Curious to hear any thoughts! Also curious if there are any potential issues that would prevent this from being  applicable to something like Risk Team outputs, or doubts about reputation systems generally in this context. ",
                    "links": [
                        "https://forum.makerdao.com/t/makerdao-needs-a-treasury-to-provide-compensation-to-its-workers-post-foundation-focus-on-workers-for-now/1091",
                        "https://s-ben.github.io/makerdao-discourse/site/timeline/forum.makerdao.com/",
                        "https://s-ben.github.io/makerdao-mcd-cdp-portal/site/timeline/makerdao/mcd-cdp-portal/",
                        "https://forum.makerdao.com/t/maker-sourcecred-trial/2551",
                        "https://forum.makerdao.com/t/mip13c3-sp6-sourcecred-funding/4545/5",
                        "https://forum.makerdao.com/t/agenda-discussion-scientific-governance-and-risk-thursday-january-23-9am-pst-5-00-pm-utc/1165/2",
                        "https://forum.makerdao.com/t/governance-initiative-experimenting-with-sourcecred/1345/10",
                        "https://forum.makerdao.com/t/acerca-del-programa-sourcecred/4654",
                        "https://forum.makerdao.com/t/sourcecred-distribution-for-week-ending-august-29th-2021/10098/5"
                    ],
                    "GPT-summary": null,
                    "GPT-proposal-categories": null,
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.340277777777778
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Adam_Skrodzki",
                    "index": "#2",
                    "likes": "0",
                    "time": "21/01/2020-10:29:32",
                    "content": "Sounds like a great way to estimate efford well. Of course it do not answer question where money comes from, but sounds like great thing to try out and estimate contributions. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 9.0
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Planet_X",
                    "index": "#3",
                    "likes": "6",
                    "time": "21/01/2020-11:25:46",
                    "content": "First of all thank you for partially including me in your chart, but I have serious objections to using any kind of algorithm to determine worker compensation. If the algorithm is secret then people are less likely to trust the result, and if the algorithm is public then the system will at some point be gamed. Please do remember that Maker workers will use their compensation to feed kids and pay mortgages so the majority of them will need to have a measure of income stability. Alice: \u201cCan we go on vacation this year, darling?\u201d Bob: \u201cI have no idea, we must wait for the algorithm to decide.\u201d ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 4.90625
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Adam_Skrodzki",
                    "index": "#4",
                    "likes": "1",
                    "time": "21/01/2020-13:36:16",
                    "content": "    Planet_X:  If the algorithm is secret then people are less likely to trust the result, and if the algorithm is public then the system will at some point be gamed.   Sounds like a valid point, but keep in mind that if algorithm starts to be gamed it can be changed (and I would argue that it even should be simply part of governance)     Planet_X:  Please do remember that Maker workers will use their compensation to feed kids and pay mortgages so the majority of them will need to have a measure of income stability.   I wonder what @s_ben thinks about it, but my understanding is that this algorithm is to reward \u201cswarm\u201d of little contributions. I expect that full time proffesionals like for example oracles, risk experts will be compensated by separate stable budget first set by Maker Foundation and finally by governance well in advance. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 4.914351851851852
                },
                {
                    "author_link": "https://forum.makerdao.com/u/LongForWisdom",
                    "index": "#5",
                    "likes": "7",
                    "time": "21/01/2020-14:45:20",
                    "content": "Hey! I won the forum. On a more serious note, Welcome to the forum @s_ben This is pretty interesting but I share many of @Planet_X\u2019s concerns regarding using algorithms to calculate this sort of thing. Also, while it isn\u2019t a data-driven point of view, I can give some anecdotal detail to how I spend my time doing MakerDAO things. So far most of the work I\u2019ve done has been on the following:  Google docs related to governance projects / MakerDAO projects Organising and stake-holding projects on rocket chat. Providing feedback to others on work that they\u2019ve completed.  Especially recently, most of the work that I view as being high-value hasn\u2019t occurred on the forums. Based on this I\u2019d argue against any algorithm that was unable to capture work on google docs and project management via rocket chat. Personally for DAO compensation I\u2019d like a system based on:  A flat minimum hourly rate based on the living wage in a first world country (as calculated by a reputable group) Additional compensation based on skills, experience and contribution. No greater than a 10x difference in hourly rates between any two workers paid by the DAO. (10x might even be too much imo.)  ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.969907407407407
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#6",
                    "likes": "0",
                    "time": "21/01/2020-17:45:18",
                    "content": "    Adam_Skrodzki:  Of course it do not answer question where money comes from, but sounds like great thing to try out and estimate contributions.   I would imagine the money would come from the same places being discussed on other threads such as Signaling Request: Should Maker make a Treasury to manage revenue?. The simplest way would be for the Foundation to fund some kind of experimental trial. But the fact that Maker has already done the hard work of setting up on-chain payments for oracles makes me excited that it could do something similar for risk teams, paying via the vault/stability fee (or similar, still learning Maker). If working on governance becomes sustainable permissionless employment, similar to how keepers are paid, I think many more people would participate. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.94551282051282
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#7",
                    "likes": "6",
                    "time": "21/01/2020-18:11:36",
                    "content": "    Planet_X:  If the algorithm is secret then people are less likely to trust the result, and if the algorithm is public then the system will at some point be gamed.   So the algorithm is public, and the intention is for it to always be. Gaming is the main potential weak point. There has been a lot of thought put into attack vectors, and how they can be mitigated. There are a couple ex-googlers working on the project, as well as a PhD social scientist that\u2019s put a lot of time into this as well. Here\u2019s a podcast where he goes into details about the algorithm, gaming, etc. if anyone wants to dig deeper. So far, the project has not seen that issue. It\u2019s been paying people for 16 weeks now according to cred scores, to dogfood it internally before recommending to others. Here are the payouts so far. The payouts started small, then ramped up to ~$15k/week in the last couple months. My personal opinion (not speaking for the project), is that in small groups of humans that know each other, gaming will not be an issue (or will but there are good mechanisms for dealing with it). Scale it out to thousands, millions, with lots of money at stake, and yes, you\u2019ll see major sibly attacks, bots, spam, etc. But for something like Maker Risk Teams, presumably we\u2019re talking about small groups of highly skilled, educated people that know each other, right?     Planet_X:  Please do remember that Maker workers will use their compensation to feed kids and pay mortgages so the majority of them will need to have a measure of income stability.   This is something SourceCred the project is grappling with right now. It wants to start recruiting developers, for instance, that can build out a deployable product. But people will expect salaries, stability. There have been a few ideas floated. For instance, a Foundation could take on the volatility risk itself. Maybe it loans the contributor DAI in the beginning, taking on risk that the contributor bails without paying off. Then the contributor pays back the DAI until they\u2019re self sufficient. Or, (and this is my case, as I make my living working for crypto in two DAOs (SourceCred and Decred)), contributors manage the volatility themselves. Keep savings knowing some months will be up, some will be down. It may be a hard pill to swallow, but this type of employment also offers a different type of security and antigragility that traditional employers cannot. Namely, there is no \u201ctail risk\u201d of being fired (income going to 0 abruptly). There are also ways to introduce stability at the algorithmic level. For instance, currently SourceCred contributors are paid via a formula (which is modify-able) that pays according to a mix of last week\u2019s contributions and \u201clifetime cred\u201d (total value of all contributions). The lifetime cred is much slower moving and stable; and could be made even slower moving and stable if desired. One can think of contributors building up a \u201cpostition\u201d in the project, similar to how traders build large positions. If the payments from that position are stable, the income becomes relatively stable. In the future, when all of this goes on-chain and permissionless, and the system generates reliable enough revenue, we could see something similar to the Bitcoin mining industry. Where there\u2019s a lot of volatility, but nonetheless, organizations creatively use their own capital and organizational skills to create their own stability. Bitcoin mining pools now generate sustainable revenue (enough to IPO on public markets even). I explore this in a fun thought piece SourceCred as Community-Store-of-Value, where I substitue PoW miners in Bitcoin with PoL (Proof-of-Labor) miners in decentralized projects. But yes, an open problem (which I have currently   ). Curious to hear any ideas around this. ",
                    "links": [
                        "https://discourse.sourcecred.io/t/sourcecred-contributor-payouts/298",
                        "https://discourse.sourcecred.io/t/sourcecred-as-store-of-community-value-socv/129"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.224454365079366
                },
                {
                    "author_link": "https://forum.makerdao.com/u/MakerMan",
                    "index": "#8",
                    "likes": "0",
                    "time": "21/01/2020-18:20:52",
                    "content": "Ben, Welcome to the forums.  I really liked you just popped something out that could be used as a basis for determining effort.   How much to reward peole - something like an alogrithim is a cheap first pass approach that literally costs almost nothing as an estimate.   And you have presented us with a pretty big piece of work and detail.   Thank you. The biggest issue with such a scoring system (reddit has been working on varying ways to implement DAO and community/posting rewards for effort - still has a long way to go really - needs to be used and a good look at whether it does represent effort) is spamming vs. real work and quality posts.   One thing I see in reddit is people effectively spamming somewhat to get their claim to a distristubion of rewards.    Will have to see whether the DAO itself will evolve this to something more appropiate.   Since rewards also give users DAO voting tokens there has been some concern of a concentration of governance power into too few hands (sound familar). I completely agree that with smaller groups who know each other well this model could work well.   Scaling it to the size of reddit - a difficult challenge which I happen to be a part of the current reddit DAO experiments. I think if since governance voting via MKR would be different than the contributions there isn\u2019t the same issue here.    As to payment criterion you have some really good ideas LFW.   I\u2019m pretty much agreed that if we set a bottom minimum payment rate (say $10/hr) I don\u2019t think we should be compensating anyone much above $100/hr or 10x that rate or that would have to be \u2018special\u2019 compensation.     Though as a consultant I have billed at over $1000/hr (legal case testimony between Apple and Sony as this required specialized hardware to be operational and literally 6 people - two lawyers, videographer, etc. at my place for the demonstation of technology) and billed for other minor consuting work at maybe 40-50 (website development) so I think the factor of 10 between the bottom and top is reasonable\u2026 ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.993303571428572
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#9",
                    "likes": "2",
                    "time": "21/01/2020-18:30:41",
                    "content": "Thanks for taking the time to express these concerns @LongForWisdom. It\u2019s valuable feedback!     LongForWisdom:  Especially recently, most of the work that I view as being high-value hasn\u2019t occurred on the forums. Based on this I\u2019d argue against any algorithm that was unable to capture work on google docs and project management via rocket chat.   So, this is a problem the project is grappling with currently. The algorithm works reasonably well at valuing work that shows up on public platforms (GitHub & Discourse for now, though one can write plugins to ingest any type of data). The project lead was just expressing frustration on the last community call actually that their emotional labor resolving a recent dispute (over a change in cred scores) was not showing up in the graph   The base PageRank algorithm is robust enough to take other inputs. One solution would be to add new heuristics that are more expressive. I explore different heuristics (and trust issues generally) in this medium article:    Medium \u2013 13 Sep 19    The DAO Missing Link: Reputation Protocols It\u2019s time to call it. 2019 is indeed the year of the Decentralized Autonomous Organization (DAO). The term DAO, once tainted by the\u2026 Reading time: 10 min read        But I would also argue (again my personal opinion, not the project\u2019s per se), that Discourse in particular may reward this \u201cinvisible\u201d labor indirectly. For instance, as you point out:     LongForWisdom:  Hey! I won the forum.   Is this not in part because people that appreciate your other efforts  and reply to your posts more? Every time someone interacts with your posts, they flow some \u2018cred\u2019 generated from their posts to you. ",
                    "links": [
                        "https://medium.com/sourcecred/the-dao-missing-link-reputation-protocols-8e141355cef2"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.373895202020202
                },
                {
                    "author_link": "https://forum.makerdao.com/u/jernejml",
                    "index": "#10",
                    "likes": "0",
                    "time": "21/01/2020-20:02:50",
                    "content": "    s_ben:  Is this not in part because people that appreciate your other efforts  and reply to your posts more?   Usernames like and reply to posts, not necessarily unique humans. There is no such thing as proof of unique identity on the internet. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.5625
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#11",
                    "likes": "2",
                    "time": "21/01/2020-21:26:35",
                    "content": "    jernejml:  Usernames like and reply to posts, not necessarily unique humans. There is no such thing as proof of unique identity on the internet.   True, the Sibyl problem is largely unsolved, for all platforms. However a) consistent work over time is a robust measure of \u201chumanness\u201d (e.g. i know you\u2019re a human:), b) Sibly problems are typically not as prominent in smaller groups (e.g. below the Dunbar number (100-250 people) people have proven the ability to keep tabs on each other); the risk governance community is likely to be below this for a long time (or partitioned off into subcommunities of this size), c) if a bot does risk analysis that other humans find valuable, what difference does it make to MakerDAO\u2019s mission? ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.339923469387755
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#12",
                    "likes": "1",
                    "time": "21/01/2020-22:01:16",
                    "content": "Thanks for the thoughtful reply.     MakerMan:  something like an alogrithim is a cheap first pass approach that literally costs almost nothing as an estimate.   There\u2019s truth to this. What excites me is that the cheap/free first pass not only get \u201cin the neighborhood\u201d for projects I\u2019ve run it on, it serves as a starting point for discussion. Indeed, SourceCred (which is paying people to dogfood, successfully so far IMO) just had a call where we decided to do weekly reviews of contribution scores. The thing is, without a starting point/framework, you\u2019ve got a blank slate, and the convo typically dies before it starts (in my experience).     MakerMan:  The biggest issue with such a scoring system (reddit has been working on varying ways to implement DAO and community/posting rewards for effort - still has a long way to go really - needs to be used and a good look at whether it does represent effort) is spamming vs. real work and quality posts. One thing I see in reddit is people effectively spamming somewhat to get their claim to a distristubion of rewards. Will have to see whether the DAO itself will evolve this to something more appropiate. Since rewards also give users DAO voting tokens there has been some concern of a concentration of governance power into too few hands (sound familar).   A fair point. Reddit is a good example/cautionary tale. I\u2019m watching the daonuts experiment closely (Reddit\u2019s first foray into on-chain tokenization of karma on r/ethtrader and governance of elements of the subreddit (e.g. controlling the banner ad)). It seems to be going well so far, but curious to hear critiques from those with more experience (admittedly am not part of the community, just playing with the systems to learn). A founder of the daunuts project was working on a SourceCred integration prior to daonuts actually. Called the CredDAO, it\u2019s a GitHub app that airdrops ERC-20 tokens according to cred scores in a GitHub repo. I\u2019m hoping to run into them at EthDenver pick their brain     SourceCred \u2013 25 Dec 19    CreDAO (SourceCred + Aragon DAOs) Description Credao is a Github App. The [rough] goal is to enable github users to install the app to their org or repo and have an Aragon dao automatically made. SourceCred cred is retrieved and used as a metric for airdropping tokens into the Aragon... Reading time: 2 mins \ud83d\udd51 Likes: 4 \u2764      Ultimately, I agree that scaling this to millions of people is likely to result in being overrun with bots/spam. Especially if enough money is involved. However, for many applications, such as Risk Teams, I imagine we\u2019re talking about a fairly small group of people will be qualified/interested; presumably below the Dunbar number (100-250). If not, the community could be forked to \u201cfork\u201d into manageable sizes, like what churches do when their congregations grow too large. Smaller groups of people are fairly good at spotting and punishing bad behavior (e.g. how many people are registered on the MakerDAO Discourse? Is it not a great place, largely free of spam (I hope this doesn\u2019t count  )? Do the initial SourceCred scores not get in the ballpark?). The system could also start out somewhat centralized, where an authority has the ability to change weights, setting spam to 0 (this is actually the way SourceCred operates currently while it explores avenues to further decentralization).     MakerMan:  I\u2019m pretty much agreed that if we set a bottom minimum payment rate (say $10/hr) I don\u2019t think we should be compensating anyone much above $100/hr or 10x that rate or that would have to be \u2018special\u2019 compensation.   This is a tricky one. While I see the desire to have one\u2019s time valued within a certain range, I\u2019m not sure time is the best valuation metric. Perhaps it is one input among others, but the most promising permissionless/decentralized systems I\u2019ve seen so far focus on a quantifiable work output (e.g. keepers are paid for liquidations, not time spent educating themselves or maintaining server infrastructure). This can be mitigated in a number of ways that \u201cde-risk\u201d taking the time to do any particular task. For instance, since I essentially get paid \u201croyalties\u201d on every contribution in the SourceCred graph (every GitHub PR/comment//etc., Discourse topic/reply/etc.), my \u201croyalty stream\u201d is fairly constant, even if I don\u2019t get paid much for a particular piece of work. E.g. I will likely write up this feedback I\u2019m getting on the SourceCred discourse, and will get paid some amount for that (maybe only a low hourly wage worth, but not $0). There are also high-level variables to tweak that can make income more or less variable, as well as financial mechanisms from the traditional finance world that could be brought to bear. E.g. debt financing (a party pays you now for a claim on future rewards), etc. ",
                    "links": [
                        "https://discourse.sourcecred.io/t/credao-sourcecred-aragon-daos/459",
                        "https://discourse.sourcecred.io/t/credao-sourcecred-aragon-daos/459",
                        "https://en.wikipedia.org/wiki/Dunbar%27s_number"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.734909456740443
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#13",
                    "likes": "0",
                    "time": "21/01/2020-22:27:35",
                    "content": "    Adam_Skrodzki:  I wonder what @s_ben thinks about it, but my understanding is that this algorithm is to reward \u201cswarm\u201d of little contributions. I expect that full time proffesionals like for example oracles, risk experts will be compensated by separate stable budget first set by Maker Foundation and finally by governance well in advance.   I go into this more at the end of my other reply to @MakerMan , but essentially yes. I haven\u2019t looked up the numbers, but I likely get a \u201croyalty stream\u201d generated from several hundred individual contributions on the SourceCred GitHub and Discourse (the two platforms it integrates with currently). There are many ways the Foundation could create stability in creative ways. For instance, one could set a threshold one needs to reach to start getting paid. One could also pay strictly according to \u201clifetime\u201d cred, which is relatively slow moving from week-to-week (the rate this varies would be an important parameter for a project to set (i.e. weight \u2018old guard\u2019 vs. \u2018new guard\u2019). In fact, if I stopped contributing to SourceCred, I would still get payments indefinitely (the way it\u2019s set up currently, and assuming investors keep buying SourceCred\u2019s token (Grain)), they would just fade to negligible amounts over time as more people contributed.     Adam_Skrodzki:  Sounds like a valid point, but keep in mind that if algorithm starts to be gamed it can be changed (and I would argue that it even should be simply part of governance)   Yes. In my personal opinion, the \u201cout-of-the-box\u201d scores when running the algorithm on individual repos/forums gets \u201cin the neighborhood\u201d, and is useful immediately (assuming you already have moderation of spam via GitHub/Discourse moderation tools, which I assume Maker already has in place). But some kind of mechanism is needed to reach consensus if you want to change parameters, or try to quantify value \u201cacross\u201d different repos/forums. While I have researched and written about Maker\u2019s Risk Governance Framework in the past (~6 mo ago wrote this summary of Maker governance paid for by Decred stakeholders using their decentralized proposal system (funding proposal), I don\u2019t have visibility into the day-to-day process and \u2018artifacts\u2019 generated by Risk Teams. Would be curious if there was something public I could check out. ",
                    "links": [
                        "https://cryptocommons.cc/daos/ethereum/maker/",
                        "https://proposals.decred.org/proposals/c68bb790ba0843980bb9695de4628995e75e0d1f36c992951db49eca7b3b4bcd"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.566761363636363
                },
                {
                    "author_link": "https://forum.makerdao.com/u/LongForWisdom",
                    "index": "#14",
                    "likes": "4",
                    "time": "21/01/2020-23:33:08",
                    "content": "@s_ben this is all really fascinating to read, a huge thank you for bringing this to the forum. This has definitely given me a lot to think about. The more I read the more I am coming around to the idea of using a data source like this as one input into a system for compensation. I\u2019m not sure I would be comfortable removing humans entirely from the system based on what you\u2019ve explained so far, but I\u2019m seeing more value in this the more I think about it. Interesting comments about the Dunbar number and the applicability to smaller communities over larger ones. I think you\u2019re correct here. I can see a system like this working better on a smaller scale than a large one. I\u2019d be curious to know if you had any thoughts on how to ensure a fair and equitable wage distribution in a system based on results rather than time spent. I\u2019m not necessarily against paying for results rather than time spent (indeed in many ways that makes more sense to me) but my priority in this area is to ensure we are paying employees in a fair an equitable manner. I do worry that if we pay for results rather than time spent that it will lead to a proliferation of low-effort high-value work. \u2026 \u2026 \u2026 I just read back that sentence and I have no idea why I\u2019d be worried about that, it actually sounds fantastic. Perhaps some of my worry can be justified in that results-driven compensation does not necessarily capture work quality. As an example lets take a Risk Model. I don\u2019t have much familiarity with that sort of work, I highly doubt that I can recognise a fully thought out, triple-checked and solid risk model versus a half-assed risk model in which the proper checks and considerations have not taken place. Under this system I think I would contribute more SourceCred to the creator for 3 half-assed risk models than a single high-quality model because I am not qualified to recognise the difference. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.101737451737453
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Sirlupinwatson1",
                    "index": "#15",
                    "likes": "0",
                    "time": "22/01/2020-01:39:20",
                    "content": "@Planet_X I strongly agree with you about this point :     Planet_X:  Alice: \u201cCan we go on vacation this year, darling?\u201d Bob: \u201cI have no idea, we must wait for the algorithm to decide.\u201d   I think this situation result with every members here and tough decision is taken sometimes. Part of the project could be done with an algorithm while another part would need human decision. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.074074074074074
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#16",
                    "likes": "2",
                    "time": "22/01/2020-02:27:50",
                    "content": "    Sirlupinwatson1:  Part of the project could be done with an algorithm while another part would need human decision.   Totally agree. The original version of SourceCred (which was scrapped and rebuilt) focused too much on the algorithm. It has since pivoted to to being focused more on being a tool for communities to reach consensus on the value of contributions. It is \u201cintersubjective\u201d, blending objective metrics and human subjectivity. The founder talks a bit about this in this podcast if anyone is interested in the broader vision.   sourcecred.podbean.com    SourceCred Podcast A podcast for all things SourceCred, a reputation protocol for open collaboration....      ",
                    "links": [
                        "https://sourcecred.podbean.com/e/dandelion-sourcecred/"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.736111111111111
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Mitote",
                    "index": "#17",
                    "likes": "3",
                    "time": "22/01/2020-03:18:29",
                    "content": "Really interesting. Looking in SourceCred more to understand better how this work and what controls/modification Maker could put on. SourceCred seems to operate primarily about work on things like code and githhub. Alot of the work around Maker to me seems harder to qualify or be verifiable, like bis dev or general communication between people/groups There are these big questions/anxieties in Maker about who and how get paid for what in a DAO based world. I feel like this community doesn\u2019t have a clear sense of what work is worth paying for. In my head I think we need to figure out what groups of activities maker holders are willing to compensate. Starting with Risk, Oracle and integrations (technical) work seems like the way forward, but some governance or community roles could be looked at. So far I think most people who believe Maker needs a budget would want to start with compensating those first three groups. Using an algorithm to determine payout saves alot of time and resources, but alot of the concerns mentioned above seem valid. We could maybe make a situation where governance allocates budgets to each \u201ccore\u201d group which are to spent by the \u201cfacilitator\u201d of each group. Instead of the facilitator just finding someone to contract or employ they could use a SourceCred type construction for compensating certain tasks that are better suited for automatizing. (maybe like comments, meetings, idk what else since I haven\u2019t really dived into it ) while still offering some contracting for other tasks not as explicit. The \u201cFacilitator\u201d would be paid a salary through a contract with governance. To do that I think first identifying potential \u201cFacilitators\u201d of each core and working with them to develop a plan for their \u201ccore\u201d makes the most sense. Cyrus for example could facilitate the risk \u201ccore\u201d and work with the community on how he could best use resources to develop financial risk framework tools and theory. With a deeper understanding of this algorithm it seems conceivable that he could automate a certain % of his budget. I dont see how the \u201ccommunity\u201d can decide how to pay financial engineer types without input from the group itself. Rich could fund incentives for governance tools, communications and activities (basically what happens now just a budget allocated by the DAO to rich) Honestly this whole topic is pretty overwhelming to me even though I initiated some of the conversation before. Hopefully we can figure out some incremental actionable step soon. Im personally working a lil project trying to roughly analysis the academic literature on organizational management architecture for the maker context. Maybe it\u2019ll be useful maybe not ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.103021978021978
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Sirlupinwatson1",
                    "index": "#18",
                    "likes": "0",
                    "time": "22/01/2020-03:44:33",
                    "content": "@s_ben I like this podcast. The more and more , people will get into this and open up for open-source contribution , contributors, projects. Great informations and this for sure could be introduced in here. Thumbs up @s_ben ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 7.3
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#19",
                    "likes": "0",
                    "time": "22/01/2020-07:50:28",
                    "content": "Would be great to see SourceCred used as an input! Happy to help explore that possibility if the community decides to pursue it.     LongForWisdom:  I\u2019m not sure I would be comfortable removing humans entirely from the system based on what you\u2019ve explained so far, but I\u2019m seeing more value in this the more I think about it.   It definitely works best when there is a well-defined problem. I would think the formulaic nature of Risk Team work (going through the Risk Governance Framework to generate analysis, reports, etc.), combined with the academic researchy nature (which is what PageRank was originally based on) could be a good fit. Though I think it also can do a good job capturing more day-to-day granular work, like is done on this forum (the algorithm and weights could be tweaked from what I\u2019ve posted to better fit Maker\u2019s needs).     LongForWisdom:  I\u2019d be curious to know if you had any thoughts on how to ensure a fair and equitable wage distribution in a system based on results rather than time spent. I\u2019m not necessarily against paying for results rather than time spent (indeed in many ways that makes more sense to me) but my priority in this area is to ensure we are paying employees in a fair an equitable manner.   This is a problem SourceCred is grappling with itself. I\u2019m happy with the way SourceCred is currently paying contributors (based on lifetime cred), because my \u201croyalty stream\u201d from past contributions has become fairly consistent over time. However, the project is looking to recruit devs and other key contributors, and they will likely have more traditional expectations around employment. A SourceCred Foundation is currently being formed, which can pay salaries or perform other functions if needed. Though the project is also exploring novel \u201cemployment\u201d mechanisms where contributors are still paid via cred scores, but are able to \u201cde-risk\u201d the volatility. For instance, the project could front new contributors cred, which assures them a certain amount per month roughtly (currently Protocol Labs is buying Grain (SourceCred\u2019s token) at a fixed exchange rate, so cred can reliably be sold for fiat). They then pay back the \u201ccred loan\u201d with contributions. Just one idea. I will say, that having worked in several Bay Area startups, and having spent the last ~1.5 years working in (and for) crypto, I find that crypto, while volatile and challenging, presents a different type of security and antifragility. I\u2019m not worried about getting fired and my income going to zero abruptly (which as happened to me). I think once people experience this \u201cpermissionless employment\u201d, lightbulbs will go off, similar to the experience of sending Bitcoin for the first time. When I post a recap of feedback I have received from this (great!) thread, I am confident I will get a number of s, which will flow cred (and $) to me.     LongForWisdom:  Perhaps some of my worry can be justified in that results-driven compensation does not necessarily capture work quality. As an example lets take a Risk Model. I don\u2019t have much familiarity with that sort of work, I highly doubt that I can recognise a fully thought out, triple-checked and solid risk model versus a half-assed risk model in which the proper checks and considerations have not taken place. Under this system I think I would contribute more SourceCred to the creator for 3 half-assed risk models than a single high-quality model because I am not qualified to recognise the difference.   There are two main ways quality can be enforced:  Value contributions higher if other \u201chigh cred\u201d contributors (who have gained reputation by producing high-quality work in the past) interact with those contributions. For instance, more cred flows to posts on Discourse if they are 'ed or replied to. This effect can be amplified if needed by tweaking the algorithm. Have a process whereby contributions are filtered. For instance, SourceCred is implementing a review culture/process, where a standard OSS GitHub process and norms are used. If a document is spam/low effort, per OSS norms, it will not get merged. And therefore get little (or 0) cred. This of course introduces a centralization factor with the maintainers. But perhaps a convenient/necessary one at this stage. Alternate governance mechanisms could be used in place of GitHub as well, which is also being discussed.  ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.08826672154137
                },
                {
                    "author_link": "https://forum.makerdao.com/u/LongForWisdom",
                    "index": "#20",
                    "likes": "0",
                    "time": "22/01/2020-10:34:54",
                    "content": "I think I may have expressed myself poorly in my last comment. I am less concerned about stability of income, and more concerned about paying a fair minimum wage. Traditionally, remuneration for positions looks something like this: Time spent x ( quality skills experience ) With SourceCred, this separation of time and quality is combined into a measure of \u2018appreciated output\u2019 (again I\u2019m not convinced this isn\u2019t better, but it\u2019s definitely different). This means that we are not able to set a minimum hourly remuneration and cannot ensure that we are paying people fairly for their time. I\u2019d be curious if there is a way of weighting or tweaking the algorithm to separate these two variables? Can SourceCred produce a quantity value (number / length of posts / commits) and a quality value (likes, replies, etc) separately? This might allow us to set \u2018quality bands\u2019 which we could use to determine hourly rate, and a \u2018quantity\u2019 value to estimate the number of hours worked. Do you have any thoughts on if this could work, or if it\u2019s even a good idea? I\u2019m also curious as to how this works in terms of absolute versus relative values. Is it accurate to say the example models you\u2019ve posted show relative contributions rather than absolute contributions? If I\u2019m understanding your own system of royalties correctly, there is a pool of income which is split between all contributors? If instead of having a fixed amount to pool we want to pay on an absolute basis (and deal with any debt incurred) is that possible? I worry that the relative contribution model could produce unhealthy competition, my contributions don\u2019t diminish those of others, but if I understand correctly if I contributed a large chunk of work that increased my royalties, it would reduce the royalties of others (because it\u2019s based on a relative weighting). ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.758818342151676
                },
                {
                    "author_link": "https://forum.makerdao.com/u/s_ben",
                    "index": "#21",
                    "likes": "4",
                    "time": "23/01/2020-08:44:25",
                    "content": "Yeah there\u2019s a lot to think through here! You bring up some important points about what SourceCred could be good for (and not) in this context, as well as some important questions about how SourceCred would integrate into a larger DAO structure. While I\u2019m not familiar enough with the DAO to make recommendations there, I can speculate about how I think SourceCred would perform for certain functions. I think SourceCred could work well \u201cout-of-the-box\u201d for valuing certain types of work (e.g. Risk work). Any time there are regularly produced \u201cartifacts\u201d (posts, comments, s, code commits, etc.), SourceCred, over time, tends to produce valuations that are \u201cin the ballpark\u201d and actionable. Or at least useful as a starting point for humans to reach consensus and continue tweaking the algorithm. Because it is based on PageRank, which was itself based on citations in academic literature, it could even work well even for more abstract, researchy things. For instance, if your literature survey on organizational management architecture was turned into a post, and that post was referenced by lots of other posts, the node representing it in the graph would acrue cred. Being the post\u2019s author, the node representing you would also acrue cred. As an example from the SourceCred graph, a post on trust levels created by a researcher that did foundational work on SourceCred\u2019s PageRank algorithm (Michael Zargham), has been referenced a large number of times. At the same time, this researcher has also done some higher level creative work that didn\u2019t make it into the graph. In the podcast interview below, he discusses this issue frankly, and delves into the limiations of the current SourceCred algorithm, and how they might be addressed.   sourcecred.podbean.com    SourceCred Podcast A podcast for all things SourceCred, a reputation protocol for open collaboration....      Currently, SourceCred does not do a good job capturing less tangible work products, which don\u2019t generate sufficient artifacts to analyze. E.g. project management, emotional labor, legal work, planning a conference, etc. The team is aware of this limitation, and has been working to address it. One strategy is heuristics. Any heuristic than can be expressed in code can be used as an input to the graph. To use a simple example, we could create a heuristic that says, \u201clonger posts represent more work and are therefore more valuable\u201d. It would be fairly easy to create a module that counts the number of words in a post and includes that in the valuation. Another approach is using \u201csupernodes\u201d, a feature which is currently in beta testing. These are abstractions that sit \u201cabove\u201d the graph, and allow the community to curate nodes representing higher level goals or values. For instance, you can create an Initiative supernode to incentivize a particular outcome or type of work product. For instance, the podcast I linked to above has an initiative. Any work related to that podcast is linked to that supernode, and will recieve a piece of any cred that flows to it. In fact, if SourceCred and Maker collaborate, cred generated from this post could potentially flow to the podcast as well. I will say that Cred is fairly \u201cpromiscuous\u201d. In my observations, it will often pick up less tangible work indirectly. For instance, if someone is behind the scenes, doing a lot of organizational work, emotional labor, etc. and has accrued some decision-making authority in the project, their Discourse posts may get more s, will they not? It\u2019s not a strong or reliable enough signal to pay people directly. But it can surface valuable insights, and can potentially be amplified to incentivize certain behavior. As an experiment, below is a SourceCred instance for the makerdao/community repo (hosted instance here). This repo appears to represent community building work, which is generally difficult to quantify. I\u2019m curious if these scores generated with the default weights make sense to @Davidutro (who appears to organize a lot of activity there), and if there are any gaping omissions.  image2152\u00d71426 347 KB      Mitote:  We could maybe make a situation where governance allocates budgets to each \u201ccore\u201d group which are to spent by the \u201cfacilitator\u201d of each group. Instead of the facilitator just finding someone to contract or employ they could use a SourceCred type construction for compensating certain tasks that are better suited for automatizing\u2026The \u201cFacilitator\u201d would be paid a salary through a contract with governance\u2026   This seems like a sensible approach. It would introduce (or continue) some necessary centralization, with \u201csub hierarchies\u201d for each group. But allow each group to have leadership and experiment with SourceCred to figure out what it worked for (or didn\u2019t), customizing it as necessary. If SourceCred does a good job at evaluating some type of work, that work can be paid for according to cred scores (or some related metric), decentralizing the process and making it more permissionless. Continuing the general Maker approach of reducing governance decisions to the selection of a small number of key parameters, SourceCred, once customized, can be steered with a small number of important parameters. For instance the alpha parameter, which controls how far cred from a particular contribution flows across the graph. Or the weighting of old vs new contributions. Phew! More overwhelm! ",
                    "links": [
                        "https://sourcecred.podbean.com/e/michael-zargham-sourcecred/",
                        "https://sourcecred.podbean.com/e/michael-zargham-sourcecred/",
                        "https://discourse.sourcecred.io/t/supernodes-moving-past-raw-activity/340",
                        "https://discourse.sourcecred.io/t/produce-sourcecred-podcast/248",
                        "https://s-ben.github.io/makerdao-community/site/timeline/makerdao/community/",
                        "https://medium.com/sourcecred/exploring-subjectivity-in-algorithms-5d8bf1c91714"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.659636013496307
                },
                {
                    "author_link": "https://forum.makerdao.com/u/Sirlupinwatson1",
                    "index": "#22",
                    "likes": "0",
                    "time": "23/01/2020-09:08:50",
                    "content": "@s_ben Hi , Thanks for this good informations there with SourceCred. I did read it all and this could be pre-defined with algorithm or script. While the Human side could still need to be there, is a good step for advance progress. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 7.0
                }
            ]
        }
    ]
}