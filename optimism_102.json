{
    "poll_list": [],
    "discourse_list": [
        {
            "thread_link": "https://gov.optimism.io/t/draft-gf-phase-1-proposal-cycle-7-gpux/2725",
            "title": "[DRAFT][GF: Phase 1 Proposal Cycle 7] GPUX ",
            "index": 2725,
            "category": [
                "\\xf0\\x9f\\x93\\x9c Grant Proposals",
                "Governance Fund: Phase 1"
            ],
            "tags": [
                "cycle-7"
            ],
            "content": [
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "1",
                    "likes": "2",
                    "time": "20/06/2022-18:18:58",
                    "content": "Project Name: GPUX (https://gpux.ai/) Project Type: Infrastructure, Marketplace Author Name: vans163 (@van163 TG) I understand that I will be required to provide additional KYC information to the Optimism Foundation to receive this grant: Yes L2 Recipient Address: vans163.eth Which Voting Cycle are you applying for?: Cycle 7 Grant category: Is this proposal applicable to a specific committee? No Project Description (please explain how your project works): We create a decentralised protocol (think IPFS) to connect GPU providers (ex-miners, onprem labs, etc) with GPU consumers (Midjourney inference/training, other AI Art, AI training, AI inference, blender animation rendering, etc). In a post-merge world this creates a cost savings of 66-95% for GPUs compared to centralised clouds. Project links:  Website: https://gpux.ai/  Twitter: https://twitter.com/gpux_ai  Discord/Discourse/Community: gpuedge  Please include all other relevant links below:  Please link to any previous projects the team has meaningfully contributed to: NEAR Protocol  github.com/near/near-sdk-as         add RNG xorshift128p   near:master \u2190 checkgpu:xorshift128p            opened 04:02PM - 19 Jan 22 UTC               vans163             +57 -1       Add a lite RNG implementation that does not write to contract storage each time.         github.com/near/near-sdk-as     \t      Potentially look at using NativeMath seedRandom            opened 04:06PM - 20 Jan 22 UTC               vans163                        enhancement                     T-dev-tools              [https://github.com/AssemblyScript/assemblyscript/pull/2053/files](https://githu\u2026b.com/AssemblyScript/assemblyscript/pull/2053/files)  Potentially look at implementing NativeMath seedRandom and seeding it with the randomSeed we get off the vrf.         github.com/near/near-sdk-as     \t      f64 does not compile            opened 06:31PM - 18 May 21 UTC             closed 08:41PM - 18 May 21 UTC               vans163                        bug              A few cases where f64 does not compile  ``` near-sdk-as@^3.0.0:   version \"3\u2026.1.0\"   resolved \"https://registry.yarnpkg.com/near-sdk-as/-/near-sdk-as-3.1.0.tgz#b1273ff6283bfe119ac51f9953d8d774d691d0ec\"   integrity sha512-31ZwYwTyPaiG7FFXGWU2u8i5l1ak0BwZCiMLdj0JIpiW4suI+hYN4PXCIf92prAAFD8HTJ5oMdsKKi3bLRwQDQ==   dependencies:     near-mock-vm \"^3.1.0\"     near-sdk-bindgen \"^3.1.0\"     near-sdk-core \"^3.1.0\"     near-sdk-simulator \"^3.1.0\" ```  ``` let total_minted2 = storage.get<f64>(\"zod_minted\", 0.0)!      ERROR AS204: Type 'f64' cannot be nullable.     static get<T>(key: string, defaultValue: T | null = null): T | null {                                             ~  in ~lib/near-sdk-core/storage.ts(178,44) ``` ``` let total_minted2 = storage.get<f64>(\"zod_minted\")  ERROR AS204: Type 'f64' cannot be nullable.     static get<T>(key: string, defaultValue: T | null = null): T | null {                                             ~  in ~lib/near-sdk-core/storage.ts(178,44) ``` ``` total_minted: u128 = \"10000000..\" (total_minted as f64) * 0.01  ERROR TS2757: Type '~lib/as-bignum/integer/safe/u128/u128' has no call signatures.     let total_minted = storage.get<u128>(\"zod_minted\", u128.Zero)!(total_minted as f64) * 0.01;                       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  in assembly/index.ts(96,22) ```         github.com/near/nearcore     \t      state changes AKA Events for clients            opened 03:33PM - 06 Jul 21 UTC             closed 02:15PM - 23 Nov 21 UTC               vans163                        C-enhancement                     A-transaction-runtime                     T-public-interfaces              So https://github.com/near/nearcore/issues/1546 was closed but it misses the mai\u2026n point, clients need a way to subscribe to events on a smart contract.  Its a very common use case to constantly check for changes when >1 parties are involved where polling constantly on sides is not an option. Neither is it an option for these clients to run full nodes locally, someone might be on their iPhone browser.  We currently are using a off chain provider to handle our events, we could move a lot more to onchain if we were able to have clients react in real time to changes via event subscriptions.          GitHub    GitHub - vans163/NCD-05--offchain-auth Contribute to vans163/NCD-05--offchain-auth development by creating an account on GitHub.      Relevant Usage Metrics: Transactions for compute, Deposits by consumers, Payouts to providers, total compute power in network, total unique accounts Optimism native: No Date of deployment/expected deployment on Optimism: After start of OP GPU-provider/ecosystem-app incentive program Ecosystem Value Proposition:  What is the problem statement this proposal hopes to solve for the Optimism ecosystem?   New category of DApps can be built, imagine AI Art (diffusion) NFT minting, the diffusion inference can happen on GPUX instead of the AWS/GCP Cloud.   How does your proposal offer a value proposition solving the above problem?   By providing the infrastructure or \u201clayer0\u201d to run said functionality required by next gen DApps on top of.   Why will this solution be a source of growth for the Optimism ecosystem?   Marketplaces in-general produce very high growth once functional. Demand for GPUs is growing fast with breakthroughs in AI (diffusion, NLP, reinforcement learning, robotics). ETH just left equivalent of 5m 3090ti without work.  Has your project previously applied for an OP grant? No Number of OP tokens requested: 300,000 Did the project apply for or receive OP tokens through the Foundation Partner Fund?: No Proposal for token distribution: How will the OP tokens be distributed?  a. 17% Engineering This is for our core team engineers and trusted compute (SGX) team (which is on contract) b. 33% Early adopter App Builder incentive This is for builders incentive building apps on GPUX, apps can be similar to StableDiffusions, Reface, GigapixelAI, GPT3, etc. c. 17% Marketting/Community So people learn about and know what GPUX is. That it exists. d. 33% Early adopter Node Incentive (fold protein to cure alzheimer\u2019s / train AI to help good causes) To bootstrap farming nodes (computers with GPUs) we want to create our own jobs for the greater good, like protein folding. This means we dont need a 2 sided market (with users and farmers, we can bootstrap the user side via this incentive pool. NEARCrowd uses similar model providing the reward to earners from their staked NEAR)  Over what period of time will the tokens be distributed?  a. 18 mon. b. As users build on the platform (6-18 mon) (we want to host a few hackathons + partner with education company to teach how to build) c. 18 mon. Everyone in crypto should know atleast that GPUX exists by 18 months. d. Linked to b., the quicker b adopts the quicker we will distribute d. But in-order for b. to adopt we need to incentivise via d.  Please list the milestones/KPIs you expect to achieve for each initiative:  a. Elixir SDK, JS SDK, Node Explorer /w Simple HTTP API (no need to integrate SDK yourself similar to using INFURA nodes) b. Individual milestones which each builder, have their apps hit 10 | 100 | 10_000 | 1m txs per day. c. Twitter scores and other marketting reach KPIs d. Node Stability, Node is honest about its capacity  How will this distribution incentivize usage and liquidity on Optimism?  Early node incentives will make it profitable to connect hardware to GPUX even if the consumer side is not fully saturated. Every transaction for shortterm compute will go through optimism, including the followup refund.  Example: A user requests 3 nodes and take 32cpucores, 128gb ram and 4 gpus from each. For a total of 96 cores, 384G ram, 12 gpus. They realize they need more time and topup their deposit for an extra 3 hours. After they finish training their neural network they request a deposit refund from the node providers. Total OP transactions 9. 1 tx to each node provider with deposit (3 total), 1tx to each node provider for topup (3+3 total). Each node provider back to the user with their refund (3+3+3 total). Why will the incentivized users and liquidity remain after incentives dry up?  The marketplace just needs to get rolling with both sides. Users will see how good the experience on GPUX is and they will not leave. Find us a platform you would use over GPUX for your spot gpu tasks and we will innovate to make said task impossible.  Stable Diffusion Example (One of the many apps that may be built on top of GPUX): (In the future the Node Explorer will have a much nicer UX. Because each node is decentralized+independent this is the UI when you directly visit a node)    https://video0.gpux.ai/api/file/download/r2mptm56fo1g1v53p39h161qd6q13djch9oq03psltiv7vjsorl0.mp4   ",
                    "links": [
                        "https://gpux.ai/",
                        "https://twitter.com/gpux_ai",
                        "https://discord.com/invite/jjBSjSF",
                        "https://github.com/near/near-sdk-as/pull/688",
                        "https://github.com/near/near-sdk-as/pull/688",
                        "https://github.com/vans163",
                        "https://github.com/near/near-sdk-as/pull/688/files",
                        "https://github.com/near/near-sdk-as/issues/690",
                        "https://github.com/near/near-sdk-as/issues/690",
                        "https://github.com/vans163",
                        "https://github.com/near/near-sdk-as/issues/548",
                        "https://github.com/near/near-sdk-as/issues/548",
                        "https://github.com/vans163",
                        "https://github.com/near/nearcore/issues/4462",
                        "https://github.com/near/nearcore/issues/4462",
                        "https://github.com/vans163",
                        "https://github.com/vans163/NCD-05--offchain-auth",
                        "https://github.com/vans163/NCD-05--offchain-auth",
                        "https://video0.gpux.ai/api/file/download/r2mptm56fo1g1v53p39h161qd6q13djch9oq03psltiv7vjsorl0.mp4"
                    ],
                    "GPT-summary": "The post is a draft proposal for a project called GPUX, which aims to create a decentralized protocol to connect GPU providers with GPU consumers. The proposal includes information about the project, its links, and the team's previous contributions. The proposal also includes details about the problem the project aims to solve, the value proposition it offers, and the milestones/KPIs expected to be achieved. The post also includes some technical details and questions about the proposal.",
                    "GPT-proposal-categories": [
                        "Grants, Funding and resource allocation",
                        "Interoperability and Scaleability",
                        "Smart contract updates",
                        "Token economics",
                        "Community and engagement"
                    ],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal",
                        "None",
                        "None"
                    ],
                    "Sentiment": 5.52830863971709
                },
                {
                    "author_link": "https://gov.optimism.io/u/Optimus",
                    "index": "2",
                    "likes": "0",
                    "time": "21/06/2022-02:37:58",
                    "content": "This looks like a very interesting proposal, and looks like meets the intention of the PGF. Do shortterm compute transactions that go through optimism use OETH or OP? ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party asking questions about proposal",
                        "3rd party giving constructive criticism of proposal",
                        "None",
                        "None",
                        "None"
                    ],
                    "Sentiment": 8.25
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "3",
                    "likes": "0",
                    "time": "22/06/2022-13:48:32",
                    "content": "It would be a stablecoin on OP to start, ideally DAI but lets see whats available. Later on we are thinking to have a more complex relationship between DAI + Potential GPUX Token where pool/swap happens to/from DAI automatically depending on what the end user wants (speculate on token VS spend/earn stable DAI). ",
                    "links": [],
                    "GPT-discussion-categories": [],
                    "Sentiment": 6.214285714285714
                },
                {
                    "author_link": "https://gov.optimism.io/u/lavande",
                    "index": "4",
                    "likes": "1",
                    "time": "13/09/2022-21:34:45",
                    "content": "Just checking in to see if you would like this proposal to be evaluated in Voting Cycle #6 according to the updated grant proposal template? ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "5",
                    "likes": "0",
                    "time": "15/09/2022-22:59:21",
                    "content": "Yes, its go time, the merge happened, ~15m GPUs stopped mining ETH. I will update it in the coming days to the updated proposal template. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "6",
                    "likes": "0",
                    "time": "21/09/2022-20:23:16",
                    "content": "I have updated this proposal to the new template. Is there anything else I need to do to be considered for voting in the next cycle? I think there might be a need to put up the proposal for voting? ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "Author of proposal is asking for feedback"
                    ],
                    "Sentiment": 5.340909090909091
                },
                {
                    "author_link": "https://gov.optimism.io/u/lavande",
                    "index": "7",
                    "likes": "0",
                    "time": "21/09/2022-20:56:05",
                    "content": "You can review the full process in the operating manual, but you\u2019ll need explicit approval from 2 delegates with >0.5% voting power by the cutoff (which was 19:00p GMT (12p PST) today, unfortunately.) You can get yours included for Voting Cycle #7 though, which begins on September 29th. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party asking questions about proposal",
                        "3rd party auditing and reviewing proposal",
                        "None of the topics listed match",
                        "None of the topics listed match"
                    ],
                    "Sentiment": 4.625
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "8",
                    "likes": "0",
                    "time": "21/09/2022-21:02:09",
                    "content": "Got it, should I start looking for the 0.5% voting power to move out of \u201cReview\u201d now? ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0
                },
                {
                    "author_link": "https://gov.optimism.io/u/lavande",
                    "index": "9",
                    "likes": "1",
                    "time": "21/09/2022-21:15:43",
                    "content": "You can move back to DRAFT for now. Here is how the next voting cycle will work: Week 1 (9/29-10/5): Community Feedback Week 2 (10/6-10/12): Delegate Review (here is when you\u2019ll need to get the 2 approvals) Week 3 (10/13-10/19): Voting So delegates are not likely to review your proposal until the week of 10/6 (although they may sooner, if they have extra time). At that time, the best way to get in touch with delegates directly is in the governance channels in our Discord  ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party asking questions about proposal"
                    ],
                    "Sentiment": 5.916666666666667
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "10",
                    "likes": "0",
                    "time": "29/09/2022-20:26:56",
                    "content": "Proposal is up as a thread in #gov-temp-check! ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.0
                },
                {
                    "author_link": "https://gov.optimism.io/u/TheDoctor",
                    "index": "11",
                    "likes": "1",
                    "time": "02/10/2022-20:34:37",
                    "content": "This is clearly a very interesting use case of a decentralized network using GPUs to solve a real computing problem. My concerns: you aim to be a super planetary computer formed by decentralized nodes with no central point of failure. I guess you are aware of the difficulty of this. Are you familiar with the Proof of useful work concept? I think it is an open problem with no proof solution running successfully. I will love to explore this problem, but in this case, there has to be (at first) a central authority verifying the amount of computing power any node is contributing to the network. Please correct me if I am wrong in this. Thanks and good luck with the proposal ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "3rd party giving constructive criticism of proposal",
                        "3rd party asking questions about proposal"
                    ],
                    "Sentiment": 6.153645833333333
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "12",
                    "likes": "1",
                    "time": "03/10/2022-01:03:02",
                    "content": "The points of failure would be similar to IPFS, BGP can go down, DNS can go down, node operators network can go down, nodes will be unreachable in that case. When saying central point of failure I meant there is no central backend (openstack, kubes, proxmox, gcp, aws, etc) tied to all the nodes (that spins up/down nodes, calculates billing or does other things). About PoUW, I was not aware but I quickly read up a bit about it, as a first-timer hearing about it I would ask : (most important) How is work verified to be useful. If its validated somehow deterministically, decimal  operations like AI weights+biases will not verify correctly in 100% of cases depending on underlying hardware/software (and how it handles decimal ops). Our approach is to proof usefulness of work by reputation, similar to why you use AWS or Hetzner or NicheCompanyB, because you found their service very good or were recommended (or got 150k$ credits and couldn\u2019t say no :P). Cant we bring this reputation on-chain where community governs the node operators autonomously, advertise a RTX3090 but train the model at the speed of a RTX3060, reputation goes down (or simply does not go up).  There are multiple approaches to this and I have not read any relevant material tackling it yet (fisherpeople, arbiters, point scoring, etc). About the \u201ccentral authority verifying the amount of computing power any node is contributing (at first)\u201d, the BDFL path is the least pain so yes. There does need to be an authority issuing some kind of reputation at least /w possible certification (100% renewable energy mix, Tier4 DataCenter, etc). With a DAO running that can be the DAO but at the early BDFL stage of a project that would most likely be GPUX itself to bootstrap the ecosystem. (one approach, the scoring approach) The authority is not really verifying that your RTX3090 does the work a RTX3090 should do, its simply giving you reputation as you receive payments and potentially verifying your physical location Tier4 DC or say carbon mix (example nodes hosted with hetzner will be certified 100% renewable https://www.hetzner.com/assets/Uploads/Oomi-sertifikaatti-tuuli+vesi-Hetzner-2022-eng.pdf). We can enforce this by the organization hosting the nodes (mom-n-pop, basement lab, Hetzner, etc) signing their nodes with their pubkey, then we assign the certifications to the organization. Then its just a simply lookup to get the rep+assigned credentials. (another approach the fisher/arbiter) This approach would indeed perhaps have a team of crafty individuals running sneaky jobs that prop for caps of the host, if the host is not providing service as advertised they can start arbitration vs the host until the quality is returns to standard. For their work they get a slash of the hosts earnings for example. But this system would be much more complex. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "Author of proposal is explaining proposal"
                    ],
                    "Sentiment": 5.363817663817664
                },
                {
                    "author_link": "https://gov.optimism.io/u/TheDoctor",
                    "index": "13",
                    "likes": "1",
                    "time": "03/10/2022-08:03:45",
                    "content": "    vans163:  hy you use AWS or Hetzner or   Thank you so much for your explanation. I love this kind of idea, especially after the merge. In my opinion, there is no future in keeping wasting GPU mining in a non-relevant PoW chain. So I started to look into Proof of Useful work but is highly technical and I need more time to read. Anyway, as far as I understand it is more plausible a reputation approach, and this could be centralized at first, and eventually a DAO could take control. Apart from the PoUW holy grail, creating a decentralized storage network or cloud computing is not easy or trivial: IPFS is the most popular p2p solution, but it has some issues when you need an upgradable BBDD. Storage: Filecoin using IPFS (interesting but with limited use) or Chia creating a proof of space system (I didn\u2019t like this approach) Cloud Computing and more similar to this project: https://internetcomputer.org/  \u2192 They sold a great number of tokens and investors felt scammed. https://fluxwhitepaper.app.runonflux.io/  \u2192 Need to learn more about it To sum up. I love this project, so much potential. Tech is complicated, but my main concern is how to create trust. We have already seen the problem of inventing a tokenomic giving ilusion of decentralisation and ending up as a piramide scam, I need to hear about a different aproach. I like that you are thinking in a stable con for payment, there\u2019s no need for a token there and most projects mix concepts. I look forward to hearing from this poject and other community feedback Best wishes PD: Some papers about proof of useful work:   PubMed Central (PMC)    Coin.AI: A Proof-of-Useful-Work Scheme for Blockchain-Based Distributed Deep... One decade ago, Bitcoin was introduced, becoming the first cryptocurrency and establishing the concept of \u201cblockchain\u201d as a distributed ledger. As of today, there are many different implementations of cryptocurrencies working over a blockchain, ...         IOHK    Introducing Ofelimos: a proof-of-useful-work consensus protocol - IOHK Blog IOG research introduces a new, provably secure, consensus protocol to minimize the energy wastage of proof-of-work blockchains         sciencedirect.com    A collaboration strategy in the mining pool for proof-of-neural-architecture... In most popular public accessible cryptocurrency systems, the mining pool plays a key role because mining cryptocurrency with the mining pool turns th\u2026      ",
                    "links": [
                        "https://fluxwhitepaper.app.runonflux.io/",
                        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515252/",
                        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7515252/",
                        "https://iohk.io/en/blog/posts/2022/08/16/introducing-ofelimos-a-proof-of-useful-work-consensus-protocol/",
                        "https://iohk.io/en/blog/posts/2022/08/16/introducing-ofelimos-a-proof-of-useful-work-consensus-protocol/",
                        "https://www.sciencedirect.com/science/article/pii/S2096720922000306",
                        "https://www.sciencedirect.com/science/article/pii/S2096720922000306"
                    ],
                    "GPT-discussion-categories": [
                        "3rd party giving constructive criticism of proposal",
                        "3rd party extending to proposal",
                        "3rd party asking questions about proposal",
                        "None of the topics listed match"
                    ],
                    "Sentiment": 6.350573844759891
                },
                {
                    "author_link": "https://gov.optimism.io/u/vans163",
                    "index": "14",
                    "likes": "1",
                    "time": "04/10/2022-00:12:21",
                    "content": "About:  IPFS /+ Filecoin \u2192 its not usable for files larger than a jpg. Even serving video is not possible at scale, most AI models are as large as a 4k HDR video file (4-5GB).  1 Video file starts using 12 CPU cores at 100% when serving it off the gateway. Chia \u2192 It does nothing useful ICP \u2192 No GPU support + you need to write code in a special language, not many people want to rewrite code. So your adoption plummets fast. Flux \u2192 They put the token first and made a complex system, where you need to like stake coins to become a host. Its way too complex and nonsensical, why do I need to buy your token to PROVIDE for your network, it should be the other way around. Buying the token should allow me to RECEIVE. Being a PROVIDEr should be free as I am reinforcing+decentralizing the network AKA giving FLUX more value. Very backwards.  I reciprocate and love the huge interest, keeps me motivated to keep building! Yes, I saw that USDC is going to go native on OP, that is pretty big I think we will use that as we were waiting for a major stablecoin to appear+be fully maintained on OP. I am checking those papers out, Ofelimos I read already. ",
                    "links": [],
                    "GPT-discussion-categories": [
                        "Criticism of other similar projects",
                        "Technical details and questions about the proposal"
                    ],
                    "Sentiment": 5.814732142857143
                }
            ]
        }
    ],
    "group_index": "102"
}