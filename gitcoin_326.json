{
    "poll_list": [],
    "discourse_list": [
        {
            "thread_link": "https://gov.gitcoin.co/t/lessons-learned-a-look-at-gitcoin-allo-alpha-rounds-and-the-path-forward-with-gitcoin-passport/13011",
            "title": "Lessons Learned: A Look at Gitcoin Allo Alpha Rounds and the Path Forward with Gitcoin Passport ",
            "index": 13011,
            "category": [
                "\\xf0\\x9f\\x8c\\xb1 Grants"
            ],
            "tags": [
                "NONE"
            ],
            "content": [
                {
                    "author_link": "https://gov.gitcoin.co/u/erich",
                    "index": "#1",
                    "likes": "11",
                    "time": "20/02/2023-14:22:23",
                    "content": "The purpose of this post-mortem is to document the experience with Gitcoin Passport during Gitcoin Allo Alpha Rounds. The goal is to understand what went well, wrong, and what can be improved to prevent similar issues from happening in the future.  Summary of the Experience During the Gitcoin Allo Alpha Rounds, donors were unable to verify their unique identity for most of the program due to infrastructure instability with Gitcoin Passport. This resulted in a significant number of donors being unable to meaningfully participate in the program because they would not be able to verify themselves for matching funding for their donations. When the infrastructure was accessible, we heard that Stamps were reset, and Passports often needed to be \u201cre-anchored.\u201d In the event users were able to verify stamps, they could then have their Passports scored to determine eligibility.  Background Gitcoin Allo Alpha Rounds were pilot grant programs hosted by GitcoinDAO on the Gitcoin Allo Protocol, which is a new and more decentralized version of the grants product. The program was aimed at supporting innovative projects in the blockchain, open-source, and regen space, with a focus on increasing the impact and reach of such projects. To ensure the fairness and transparency of the program, Gitcoin Grants operates on a democratic matching funding mechanism called Quadratic Funding. Based on previous experience, the grants programs may be manipulated by participants who create multiple accounts/wallets to influence the matching funding results. To address this issue, Gitcoin Passport was introduced as a decentralized identity verification tool that allows participants to prove their unique humanity through various identity providers. During the round, Gitcoin Passport worked by linking a participant\u2019s digital identity to their Ethereum wallet address on the Ceramic Network, and then verifying their identity through trusted identity providers. This ensured that each participant can only have one account, and that their vote and donation are tied to their unique identity.  Timeline of Experience  2023/01/18: Users reported issues with Ceramic Network, with a CORS policy blocking requests and 504 Gateway timeout error. The team attempted to debug, restarted IPFS, and waited for feedback from Ceramic. 2023/01/19: Users experienced issues with Passports and verification process. The team advised users to be patient and were compiling an issues log. Kyle reported a few steps in place to resolve the issue. 2023/01/20: A user reported difficulty with Twitter, Discord, and ENS verification stamps. Kyle asked for an update and Gerald mentioned they were close to a fix. 2023/01/21: Ceramic network became unhealthy causing an outage and issues with the Gitcoin Passport App. Gerald worked on fixing the problem and deployed a fix for the error pop-up. 2023/01/22: The team deployed a fix for the Ceramic Network Error and moved the Passport App to AWS Amplify in an effort to resolve the server side errors we were seeing. Some web2 stamps didn\u2019t work due to the domain, but they would be fixed with a domain change. Gerald identified a bug in the reset flow causing an infinite loop error. 2023/01/23: The issue of chunks not loading persisted, with a high rate of 4xx errors in Amplify. Gerald sought assistance from Kammerdiener for the issue, which only affected the Passport App. 2023/01/24: Two separate issues were discussed regarding the Ceramic Network Error, one for the Grant Explorer page and one for the Gitcoin passport page. The team tried to improve the situation by increasing the number of worker threads. 2023/01/25: Some users reported slow performance and issues with loading their passport. Gitcoin pushed an upgrade for the Ceramic node. Another user reported that stamps could not be verified with \u201ctoo many open files\u201d error. 2023/01/26: The team attempted to resolve issues with Passport Stamps and timeouts by restarting IPFS and Ceramic nodes and considered a caching layer. 2023/01/27: Passport connections continued to time out on the Gitcoin platform. Gerald restarted the nodes and considered scripting a restart every 3 hours. Kammerdiener suggested using AWS commands for a redeploy. Product and engineering teams start considering and exploring a hotfix to the issues by migrating Passport data over from Ceramic to a centralized \u201ccache\u201ddatabase. 2023/01/28: Passport app still not working, despite servers being restarted every 2 hours. The team attempted to resolve the issue by restarting nodes but with no success. 2023/01/29: Many errors are reported by the Passport app and in Datadog. The team tried restarting the Ceramic node but with no success. The idea of using a second Ceramic node is discussed, but it will result in a delay as the node has to sync. Good progress has been made on cache, but the challenge remains in migrating to a new data strategy. Passport app still not working for some team members. 2023/01/30: Team works on fixing Passport app and Ceramic Network Error. They try various methods including changing ENS stamps. Joel from Ceramic suggests turning off pub-sub could solve the issue. New build deployed and team monitors logs, but couldn\u2019t find any issues. Some team members succeed in removing/adding stamps, while others face trouble. The team tweets they\u2019re working on the issue, but node is not functioning properly again by the end of day. Team notices a wave pattern of requests trending downwards and erroring out, then spiking back up. 2023/01/31: Ceramic returns to problematic state. The team decides to switch to its own database for Passport instead of relying on Ceramic. The community is informed of the change and development begins to migrate Passport away from Ceramic as the primary database.   The Triggering Event or Root Cause of the Incident  1386\u00d7407 79.1 KB  Gitcoin Passport requests on Ceramic in Gitcoin Grants Round 15, Source: Ceramic team The incidents that occurred during the recent Passport app were a result of increased load on the Ceramic node. Although the total number of participating donors was lower in this round compared to Grants Round 15, the number of write requests to the Ceramic node was higher due to the fact that a solid Passport score (derived through verifying various stamps) was mandatory in order to receive matching, while in GR15 it was just a boost.  |624x351.634421508098971154\u00d7651 102 KB  Gitcoin Passport requests on Ceramic in Gitcoin Allo Alpha Rounds, Source: Ceramic team Despite efforts to resolve the issue by restarting the Ceramic node and its underlying IPFS nodes, the problem persisted. The Ceramic and Passport teams observed a wave pattern of failing requests trending downward and then spiking back up, but were unable to identify the root cause of the issue and corresponding fix during the round.  Customer Impact The incident had a significant impact on Gitcoin\u2019s brand, with many users expressing frustration on platforms like Twitter and the Gitcoin Discord. The user impact of the incident was that the Passport app was not working and loading properly, causing inconvenience for the users, especially for those participating in the Gitcoin Allo Alpha Rounds. The team worked to resolve the issue and communicate with the community about the changes being made.  1600\u00d7954 125 KB  Source: https://twitter.com/EnormousRage/status/1618922283829178369?s=20  Direct Outcomes As a result of the ongoing issues with the Ceramic infrastructure, the team decided to migrate Passport to its own database instead of relying on Ceramic as the primary database. This change in plans allows users to verify their participation after the round ended within a grace period. In other words, we have taken steps to migrate the Passport app and Scorer so that they read from and write to our centrally hosted database instead of Ceramic. We plan to work on migrating Passports to Ceramic in the background.  Preventive Measures in Future Rounds To prevent similar issues from occurring in future rounds, we have identified the need for rigorous load testing to be conducted prior to a round to reveal potential issues with Passport. We are taking the following preventive measures:  Relying on a new PostgreSQL instance for the Gitcoin Passport as the primary cache database. Exploring on-chain solutions for Passport to benefit from the reliable uptime and data availability on blockchains. The Ceramic team acknowledges the experienced instability and supports a primary cache database mitigation proposed as an intermediate solution. Meanwhile, Ceramic is committed to conducting rigorous load testing and making improvements to ensure the stability of the Ceramic system for future rounds. Ceramic is dedicated to the Gitcoin Passport mission and is determined to make Gitcoin Passport reliably composable across web3.   Risk and Mitigation Strategies  Improve communication and attention to issues:   Increase transparency by providing more frequent updates to the community about the status of Gitcoin Passport and any issues that arise. Enhance the monitoring and alert systems to quickly identify and address any potential issues. Implement a protocol for reviewing and addressing community feedback to improve Gitcoin Passport   Ensure reliability and scalability of centrally hosted Gitcoin Passport database:   Conduct regular audits and testing of the database to identify potential issues and ensure that it is functioning properly. Implement redundancy and backup measures (i.e., via Ceramic, on-chain solutions, and more) to minimize the risk of data loss. Evaluate the need for additional infrastructure and capacity to support future growth.   Enhance collaboration with Ceramic team:   Establish clear lines of communication and collaboration with the Ceramic team to prevent similar issues from occurring in the future. Regularly review and assess Gitcoin Passport\u2019s architecture and infrastructure to ensure compatibility and reliability with the Ceramic network. Foster an ongoing dialogue with the Ceramic team to identify potential risks and vulnerabilities and develop appropriate mitigation strategies.  ",
                    "links": [
                        "https://gov.gitcoin.co/uploads/db4391/original/2X/9/97e89ecc5006c6bdd52c0a8dd6800860b5f6be6e.png",
                        "https://gov.gitcoin.co/uploads/db4391/original/2X/9/9ec63032b6213258e864ec47e3bde75824e2fee3.jpeg",
                        "https://twitter.com/EnormousRage/status/1618922283829178369?s=20",
                        "https://gov.gitcoin.co/t/gitcoin-program-alpha-round-post-op-writeup/13043",
                        "https://gov.gitcoin.co/t/proposal-ratify-the-results-of-january-s-alpha-rounds-and-formally-request-the-community-multisig-holders-to-payout-matching-allocations/13277"
                    ],
                    "GPT-summary": null,
                    "GPT-proposal-categories": [
                        "Identity and reputation systems",
                        "Privacy, Security and risk management",
                        "Interoperability and Scaleability",
                        "Grants, Funding and resource allocation",
                        "Law and regulations"
                    ],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.49606672788491
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/Maxwell",
                    "index": "#2",
                    "likes": "5",
                    "time": "21/02/2023-18:21:48",
                    "content": "This is amazing! Thank you so much for taking the time to write this up, Erich. Lots of learnings, and excited for Gitcoin to continue to grow, develop, and deliver outstanding products. Thanks again for the honest, vulnerable, and detailed reflection here. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.578125
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/tjayrush",
                    "index": "#3",
                    "likes": "1",
                    "time": "22/02/2023-00:42:11",
                    "content": "    erich:  relying on Ceramic as the primary database.   This is an excellent article. Thanks so much for posting. I wanted to highlight the above quote. That\u2019s the root of the problem. \u2026writer steps up on soapbox IPFS, Ceramic, Ethereum are peer-to-peer. By funneling all users through a website, you\u2019re taking a many-to-many relationship and forcing it through a many-to-one-one-to-many relationship. You\u2019ve eliminated a massive amount of connections. Plus, you\u2019ve removed the fact that in a true peer-to-peer network each participant brings some of their own resources to the party (in the form of storage and/or compute). It\u2019s not surprising that you had to add a SQL database. SQL databases are designed (very well) to serve as the to-one-one-to in the above relationship. The trouble isn\u2019t that Ceramic is not a good database, nor is the solution that Ceramic needs to become a better database. The trouble is that your app isn\u2019t peer-to-peer. That\u2019s where your efforts should be spent. \u2026writer steps down ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.616013071895425
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/kyle",
                    "index": "#4",
                    "likes": "1",
                    "time": "22/02/2023-01:43:43",
                    "content": "    tjayrush:  The trouble is that your app isn\u2019t peer-to-peer.   I appreciate this! I want to confirm I am understanding the feedback here. I suspect that by posting these details on chain, might help resolve this? I would love your thoguhts on what making Passport \u201cpeer to peer\u201d means to you.  ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.625
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/tjayrush",
                    "index": "#5",
                    "likes": "4",
                    "time": "22/02/2023-04:01:51",
                    "content": "It\u2019s very complicated, I think. And it requires the \u201cpeers\u201d to be actual \u201cpeers.\u201d By that, I quite explicitly mean, that the normal, web 2.0 \u201cclient-provider\u201d model has to be upset. It\u2019s a radical position, I know, but I think that as long as \u201cdevelopers\u201d build \u201csystems\u201d using web 2.0 APIs that \u201cserve services to humans\u201d you will never create a true peer-to-peer system. The word \u201cpeer\u201d means something. I think it means \u201cequal peer.\u201d In a provider-client relationship the \u201cpeers\u201d are not equal. The \u201cprovider\u201d sets the rules of the game. The \u201cprovider\u201d determines what happens to the data \u2013 because the data is physically on the \u201cprovider\u2019s\u201d hardware. The \u201cprovider\u201d pays for the hardware. In a true peer-to-peer system, every peer provides resources (compute, hard drive space, etc.) and carries their fair share of the burden. This massively lowers the cost of the system for the provider. That\u2019s important. If the provider is able to massively lower their costs, they\u2019re not so heavily pressured to monetize the user. If a user is being monetized, she\u2019s not a true peer. As I said above, it\u2019s very complicated. But, I think, if we never start the process and continue to build on top of what I call \u201can old-fashioned web 2.0 tech stack,\u201d we\u2019ll never solve the problems we\u2019re trying to solve. A really amazing place to start thinking about this stuff is in this document: Local-first software: You own your data, in spite of the cloud. It\u2019s one of the things that lit my mind on fire five years ago. By the way \u2013 I did indicate above that I was on a soapbox. I know what I\u2019m saying is a bit radical and that it\u2019s not easy, so there\u2019s that. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.231570512820513
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/DisruptionJoe",
                    "index": "#6",
                    "likes": "2",
                    "time": "22/02/2023-14:31:02",
                    "content": "I think we can start by running our own node with Trueblocks indexing. Then, we can realize the efficiency and performance gains along with the cost reduction of the decentralized storage for data. Then perhaps we begin acquiring peers on the network. Every program manager with more than say $100k has a pretty strong incentive to run a peer if we can package the image properly to make it as easy as possible. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.583333333333333
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/pcfreak30",
                    "index": "#7",
                    "likes": "1",
                    "time": "26/02/2023-00:26:30",
                    "content": "Ironically my project (Lume Web, lumeweb.com), which is also a Gitcoin project grantee, is innovating development on true web3 infrastructure as I see the same problems. We call everything web3, but it\u2019s really just web2 + blockchain (even AWS was used here). I, however, cannot say anything I\u2019m engineering would have solved these issues, though my tribe is a decentralized storage network  . I find this writeup interesting as it exposes bottlenecks in Ceramic at scale that force the need for a web2 centralized system that just talks to a crypto/web3 database to get information. Broadly speaking the more decentralized something is, the more inefficient it is by definition. So I might call the passport a self-hosted identity system that uses web3 technology. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.508928571428571
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/tjayrush",
                    "index": "#8",
                    "likes": "1",
                    "time": "27/02/2023-02:18:00",
                    "content": "    pcfreak30:  Broadly speaking the more decentralized something is, the more inefficient it is by definition.   I don\u2019t agree with this. I would slightly modify it to say, \u201cIf one tries to force a decentralized system through centralized pipelines, then this will be more inefficient that both pipelines.\u201d If a truly decentralized system is working in a truly decentralized way, it\u2019s significantly more efficient than a centralized system. In both cost (per participant) and speed (if well designed) and especially resiliency and censorship resistance. It depends what you\u2019re optimizing for. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.122395833333334
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/pcfreak30",
                    "index": "#9",
                    "likes": "1",
                    "time": "27/02/2023-02:45:05",
                    "content": "    tjayrush:  It depends what you\u2019re optimizing for.   It depends on what you are targeting, but I view this more from a blockchain POV. The more centralized leadership that exists, the faster you innovate. But the more decentralized (BTC) the harder it is to agree on the time of day and thus no leadership at all. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 6.75
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/DisruptionJoe",
                    "index": "#10",
                    "likes": "0",
                    "time": "10/03/2023-15:34:35",
                    "content": "Is there a good way for us to estimate the minimum viable decentralization needed for something like Ceramic or Trueblocks to operate efficiently for our use case? For example, could we use math/engineering to know that \"if we had 5 or more nodes, we wouldn\u2019t have run into passport issues on ceramic until > 60,000 donors accessing it) Also, how does a truly decentralized system handle ddos attacks? Is it simply resiliant because of the increased needs to ddos all of the nodes? ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 7.0
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/tjayrush",
                    "index": "#11",
                    "likes": "2",
                    "time": "10/03/2023-21:14:16",
                    "content": "It\u2019s very hard for me to express these ideas, so you\u2019ll bear with me as I stumble through\u2026   I\u2019m not sure add more \u201ctrueblocks\u201d nodes would ever help the situation. TrueBlocks is local first and intended to support a single user. In that case, it\u2019s very fast because it\u2019s not rate limited or shared.   If you\u2019re hoping to support many \"data scientists\u2019 or many \u2018users,\u2019 then perhaps a local-first, single-user-focused tool is not quite right.   Web 2.0 SQL databases are excellent at serving data to many clients and many users.   Blocks only appear once every 12 seconds, so there\u2019s tons of time to process data.   I\u2019ve been thinking lately that TrueBlocks should not be seen as an API server. It\u2019s not that. It\u2019s a data extraction tool. One of the tools we\u2019re working on is called \u2018monitoring\u2019 whereby TrueBlocks watches the end of the chain, extracts any needed data at each new block and puts it somewhere, and then goes to sleep waiting for the next block. \u201cPutting it somewhere\u201d currently means writing the data to a .csv file on disc, but it could be modified to push the data into a regular web 2.0 SQL database. In that way, you can use TrueBlocks to extract deep data and not use it for something it\u2019s not good at (serving data to many users). You can use regular, old-fashioned SQL API server to serve as many users as you like. As far as decentralization, SQL (of course) doesn\u2019t help there at all, but there could be some sort of post processing done (on the SQL database) to create any sort of structures one might like. TrueBlocks itself already decentralizes the index of addresses, so simply by running it as a monitoring tool, it would decentralize the index by creating, pinning and publishing the IPFS hashes. As I said, bear with me as I try to learn how to articulate the ideas behind TrueBlocks. They\u2019re subtle and they don\u2019t work the way we might expect. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.554453463203464
                },
                {
                    "author_link": "https://gov.gitcoin.co/u/griff",
                    "index": "#12",
                    "likes": "5",
                    "time": "16/03/2023-11:12:06",
                    "content": "    erich:  To prevent similar issues from occurring in future rounds, we have identified the need for rigorous load testing to be conducted prior to a round to reveal potential issues with Passport.   I think that is the big one\u2026 basically a dress rehearsal before launch will find all the catastrophic issues\u2026 and lots of the minor ones too. Overall though, if you look passed this glaring issue there were a lot of wins with passport this round, I am VERY bullish on Passport, and know several groups excited to build on and fork. Don\u2019t let one oversight cloud the incredible leap in meta-identity that you all are making. ",
                    "links": [],
                    "GPT-discussion-categories": null,
                    "Sentiment": 5.473214285714285
                }
            ]
        }
    ],
    "group_index": "326"
}